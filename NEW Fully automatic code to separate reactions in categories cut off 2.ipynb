{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2024-03-07\n",
      "Using license file /home/schwartzlab/gurobi.lic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cobra.test\n",
    "import os\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "from cobra.flux_analysis import (\n",
    "    single_gene_deletion, single_reaction_deletion, double_gene_deletion,\n",
    "    double_reaction_deletion)\n",
    "\n",
    "import cobra\n",
    "from cobra.test import create_test_model\n",
    "cobra_config = cobra.Configuration()\n",
    "cobra_config.solver = \"gurobi\"\n",
    "model = create_test_model(\"textbook\")\n",
    "model.solver\n",
    "\n",
    "a = cobra.io.read_sbml_model(\"iEC1344_C.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "single-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['EX_cm_e', 'EX_cobalt2_e', 'EX_colipa_e', 'EX_colipap_e', 'EX_crn_e', 'EX_crn__D_e', 'DM_4crsol_c', 'EX_cu2_e', 'DM_5drib_c', 'EX_cyan_e', 'DM_aacald_c', 'DM_amob_c', 'DM_mththf_c', 'EX_glyb_e', 'EX_gthox_e', 'BIOMASS_Ec_iJO1366_WT_53p95M', 'BIOMASS_Ec_iJO1366_core_53p95M', 'EX_14glucan_e', 'EX_15dap_e', 'EX_h2o2_e', 'EX_hacolipa_e', 'EX_halipa_e', 'EX_34dhpac_e', 'EX_hg2_e', 'EX_his__L_e', 'EX_4hoxpacd_e', 'EX_5mtr_e', 'EX_cys__D_e', 'EX_ile__L_e', 'EX_acgal_e', 'EX_inost_e', 'EX_k_e', 'EX_kdo2lipid4_e', 'EX_acolipa_e', 'EX_adocbl_e', 'EX_leu__L_e', 'EX_lipa_e', 'EX_lipa_cold_e', 'EX_ag_e', 'EX_lipoate_e', 'EX_ala_B_e', 'EX_malthx_e', 'EX_maltpt_e', 'EX_malttr_e', 'EX_maltttr_e', 'EX_arbt_e', 'EX_meoh_e', 'EX_met__D_e', 'EX_aso3_e', 'EX_met__L_e', 'EX_metsox_R__L_e', 'EX_metsox_S__L_e', 'EX_mg2_e', 'EX_mincyc_e', 'EX_btn_e', 'EX_mmet_e', 'EX_mn2_e', 'EX_ca2_e', 'EX_cbi_e', 'EX_mobd_e', 'EX_n2o_e', 'EX_na1_e', 'EX_nac_e', 'EX_cbl1_e', 'EX_cd2_e', 'EX_chol_e', 'EX_cl_e', 'EX_ni2_e', 'EX_nmn_e', 'EX_dms_e', 'EX_novbcn_e', 'EX_o16a4colipa_e', 'EX_doxrbcn_e', 'EX_o2s_e', 'EX_xtsn_e', 'EX_pacald_e', 'EX_zn2_e', '12DGR120tipp', '12DGR140tipp', '12DGR141tipp', '12DGR160tipp', 'EX_phe__L_e', 'EX_pheme_e', 'EX_pnto__R_e', '12DGR161tipp', '12DGR180tipp', '12DGR181tipp', '14GLUCANtexi', 'EX_eca4colipa_e', '23CAMPtex', '23CCMPtex', 'EX_pydam_e', '23CGMPtex', '23CUMPtex', '23DAPPAt2pp', '23DAPPAtex', '23PDE2pp', '23PDE4pp', 'EX_pydx_e', 'EX_pydxn_e', 'EX_rfamp_e', '23PDE7pp', '23PDE9pp', 'EX_enlipa_e', 'EX_sel_e', '26DAHtex', 'EX_slnt_e', 'EX_so2_e', 'EX_so3_e', 'EX_spmd_e', 'EX_tcynt_e', 'EX_thm_e', 'EX_tma_e', 'EX_tsul_e', 'EX_ttrcyc_e', 'EX_tungs_e', 'EX_tyr__L_e', '34dhpactex', '3GMPtex', '3AMPtex', '3CMPtex', 'EX_fuc__L_e', '3HAD40', '3HAD60', '3HAD80', '3HCINNMH', 'AADDGT', 'AAMYLpp', '3HPPPNH', '3KGK', 'AB6PGH', '3NTD2pp', '3NTD4pp', '3NTD7pp', 'EX_fusa_e', '3NTD9pp', '3OAR40', 'ACACt2pp', 'ACACtex', '3OAR60', '3OAR80', 'ACANTHAT', 'ACBIPGT', '3OAS60', 'ACGAL1PPpp', 'ACGAL1Ptex', 'ACGALtex', 'ACGAM1PPpp', 'ACGAM1Ptex', 'ACGAMT', '3OAS80', '3PEPTtex', '3UMPtex', '42A12BOOXpp', 'ACGAptspp', 'ACGAtex', '4HOXPACDtex', '4HTHRS', 'ACHBS', 'ACMAMUT', '4PEPTtex', 'ACMANAptspp', 'ACMANAtex', 'ACMUMptspp', 'ACMUMtex', 'ACNAMt2pp', '5DOAN', '5MTRtex', '5MTRtpp', 'A5PISO', 'ACNAMtex', 'ACNML', 'ACOAD1f', 'ACOAD2f', 'ACOAD3f', 'ACONIs', 'ACONMT', 'AGt3', 'AHCYSNS', 'ACPS1', 'ALAALAtex', 'ADCL', 'ADCS', 'ALATRS', 'ADMDC', 'ADNt2pp', 'ALDD4', 'ADNtex', 'EX_gbbtn_e', 'ADOCBIK', 'ADOCBLS', 'ADOCBLabcpp', 'ADOCBLtonex', 'ALLK', 'ALLPI', 'ALLULPE', 'ALLabcpp', 'EX_gdp_e', 'ALLtex', 'ANS', 'ALTRH', 'AMALT1', 'AMANAPEr', 'AMANK', 'AGMHE', 'AGMtex', 'AMAOTr', 'AMMQLT8', 'AMPMS2', 'AMPTASEPG', 'AMPtex', 'AOXSr2', 'ANHGMtex', 'ANPRT', 'AP5AH', 'ASPTRS', 'APCS', 'ASR', 'CDGR', 'CDGS', 'CDPMEK', 'CFAS160E', 'CFAS160G', 'CFAS180E', 'ATPPRT', 'BALAtex', 'CFAS180G', 'CGLYtex', 'CHLtex', 'BMOCOS', 'BMOGDS1', 'BMOGDS2', 'CHOLD', 'CHORM', 'BTNt2ipp', 'BTNtex', 'BTS5', 'CHORS', 'CHRPL', 'CHTBSptspp', 'CHTBStex', 'BUTSO3abcpp', 'CINNDO', 'BUTSO3tex', 'BUTt2rpp', 'BUTtex', 'BWCOGDS1', 'BWCOGDS2', 'BWCOS', 'CA2tex', 'CADVtpp', 'CBIAT', 'CBItonex', 'CBIuabcpp', 'CBL1abcpp', 'CBL1tonex', 'CBLAT', 'CLt3_2pp', 'CLtex', 'CMPtex', 'CCGS', 'CD2tex', 'COBALT2tex', 'APPLDHr', 'COLIPAKpp', 'COLIPAPabctex', 'COLIPAabcpp', 'APRAUR', 'CPMPS', 'CPPPGO', 'CPPPGO2', 'CRNBTCT', 'CRNCAR', 'CRNCBCT', 'ARAI', 'CRNCDH', 'CRNDCAL2', 'CPH4S', 'CRNDtex', 'CRNt7pp', 'DADNt2pp', 'CRNtex', 'DADNtex', 'CSNtex', 'DAMPtex', 'DAPAL', 'DAPDC', 'DAPE', 'DAPabcpp', 'DAPtex', 'CU2tex', 'DB4PS', 'DBTS', 'CUtex', 'CYANST', 'CYANSTpp', 'CYANtex', 'CYNTAH', 'CYNTt2pp', 'DC6PH', 'DCAtex', 'DCMPtex', 'CYNTtex', 'DCYTt2pp', 'DCYTtex', 'DDCAtexi', 'DDGALK', 'CYSDabcpp', 'CYSDtex', 'CYSSADS', 'DDGLCNt2rpp', 'DDGLCNtex', 'CYSTL', 'CYSTRS', 'DDPA', 'DDPGALA', 'DGMPtex', 'DGSNt2pp', 'DGSNtex', 'DHAD2', 'ARBTptspp', 'CYTDt2pp', 'CYTDtex', 'ARBTtex', 'DHBD', 'DHCIND', 'DHCINDO', 'DHDPRy', 'DHQTi', 'DHDPS', 'DHFS', 'DHMPTR', 'DHNAOT4', 'DHNCOAS', 'DHNCOAT', 'DIMPtex', 'DINSt2pp', 'DINStex', 'DKGLCNR1', 'DHNPTE', 'DMATT', 'DHPPD', 'DMQMT', 'DHPPDA2', 'ARBtex', 'DHPS2', 'DHPTDCs2', 'DHPTDNR', 'DMSOtex', 'DMSOtpp', 'DMStex', 'DNMPPA', 'DNTPPA', 'DHPTDNRN', 'DHPTPE', 'DHQS', 'DOPAtex', 'DPCOAK', 'DPR', 'ECAP1pp', 'ECAP2pp', 'ECAP3pp', 'ECAtpp', 'DSBCGT', 'DSBDR', 'DSERtex', 'DTARTD', 'ECOAH1', 'ECOAH2', 'ECOAH3', 'DTMPtex', 'DUMPtex', 'DURIt2pp', 'DURItex', 'EDTXS1', 'EDTXS2', 'EDTXS3', 'EDTXS4', 'EGMEACPR', 'ARGTRS', 'DXPRIi', 'DXPS', 'DXYLK', 'E4PD', 'EPMEACPR', 'ETHSO3abcpp', 'ETHSO3tex', 'ARGtex', 'F6Pt6_2pp', 'F6Ptex', 'ASCBPL', 'FACOAL80t2pp', 'ASCBptspp', 'FALDH2', 'FALDtex', 'FALDtpp', 'FACOAL100t2pp', 'ASCBtex', 'FALGTHLs', 'FCI', 'FCLK', 'FCLPA', 'FCLT', 'FDMO', 'FDMO2', 'FDMO3', 'FDMO4', 'FDMO6', 'FFSD', 'FMETTRS', 'FE3DCITabcpp', 'FE3DCITtonex', 'FE3DHBZR', 'FE3DHBZSabcpp', 'FE3DHBZStonex', 'FMNAT', 'ASNTRS', 'FORCT', 'FRUK', 'FRULYSDG', 'FRULYSE', 'FRULYSK', 'FRULYSt2pp', 'FRULYStex', 'FRUURt2rpp', 'FRUURtex', 'FRUptspp', 'FRUtex', 'FUCtex', 'FUMtex', 'ASO3t8pp', 'G1PPpp', 'G1PTT', 'ASO3tex', 'G1Ptex', 'G2PP', 'GHBDHx', 'ASP1DC', 'G3PCabcpp', 'G3PCtex', 'G3PEtex', 'G3PGtex', 'G3PIabcpp', 'G3PItex', 'G3PSabcpp', 'G3PStex', 'GLCATr', 'G6Pt6_2pp', 'G6Ptex', 'GAL1PPpp', 'GAL1Ptex', 'GALBDtex', 'GLCRAL', 'GLCRD', 'GLCRt2rpp', 'GLCRtex', 'GALCTD', 'GALCTLO', 'GALCTND', 'GALCTNLt2pp', 'GALCTNLtex', 'GLCTR1', 'GLCTR2', 'GALCTNt2pp', 'GALCTNtex', 'GALCTt2rpp', 'GALCTtex', 'GLCUR1Ptex', 'GLCURt2rpp', 'GLCURtex', 'GALKr', 'GALM2pp', 'GALS3', 'GALTptspp', 'GALTtex', 'GALURt2rpp', 'GALURtex', 'GLNTRS', 'GALtex', 'GLNtex', 'GAM6Pt6_2pp', 'GAMAN6Ptex', 'GAMptspp', 'GAMtex', 'GLTPD', 'GBBTNtex', 'GCALDD', 'GDMANE', 'GDPtex', 'GLYBtex', 'GLYC2Pabcpp', 'GLYC2Ptex', 'GUI1', 'GUI2', 'GUR1PPpp', 'H2O2tex', 'HXAtex', 'H2tex', 'H2tpp', 'I2FE2SR', 'I2FE2SS', 'HBZOPT', 'HCINNMt2rpp', 'I2FE2SS2', 'I2FE2ST', 'I4FE4SR', 'HCINNMtex', 'I4FE4ST', 'HDCAtexi', 'HDCEAtexi', 'ICHORT', 'HEMEOS', 'ICYSDS', 'HEPK1', 'HEPK2', 'HEPT1', 'HEPT2', 'IG3PS', 'HEPT3', 'HETZK', 'IGPDH', 'IGPS', 'ILETA', 'HG2tex', 'ILETRS', 'ILEtex', 'HISTD', 'HISTP', 'HISTRS', 'IMPtex', 'HIStex', 'HKNDDH', 'HKNTDH', 'HMBS', 'HMPK1', 'INDOLEtex', 'INOSTt4pp', 'INSTtex', 'INSt2pp', 'INStex', 'IPDDI', 'HOPNTAL', 'HPPK2', 'HPPPNDO', 'HPPPNt2rpp', 'HPPPNtex', 'IPMD', 'IPPMIa', 'IPPMIb', 'IPPS', 'ISETACabcpp', 'HSST', 'HSTPT', 'ISETACtex', 'K2L4Aabcpp', 'K2L4Aabctex', 'KARA2', 'KDOCT2', 'GLYTRS', 'KDOPP', 'KDOPS', 'KG6PDC', 'Ktex', 'LA4NTpp', 'LACZpp', 'LALADGLUtex', 'LALADGLUtpp', 'LALALGLUtex', 'LALALGLUtpp', 'GMAND', 'LCTStex', 'LEUTAi', 'LEUTRS', 'GMHEPAT', 'LEUtex', 'LIPACabcpp', 'LIPAHT2ex', 'GMHEPK', 'LIPAHTex', 'LIPAMPL', 'LIPATPT', 'LIPAabcpp', 'LIPOS', 'LIPOt2pp', 'GMHEPPA', 'LIPOtex', 'LPADSS', 'LYSDC', 'LYSTRS', 'LYStex', 'LYXI', 'LYXt2pp', 'LYXtex', 'M1PD', 'MALCOAMT', 'MALDDH', 'MALDt2_2pp', 'GMPtex', 'MALDtex', 'MANAO', 'MANGLYCptspp', 'MANGLYCtex', 'MALTATr', 'MALTHXtexi', 'MANPGH', 'MANptspp', 'MANtex', 'MALTPTtexi', 'MALTTRtexi', 'MALTTTRtexi', 'MALTptspp', 'MALTtexi', 'GOFUCR', 'MCPST', 'MCTP2App', 'MDDCP2pp', 'MAN6PI', 'MAN6Pt6_2pp', 'MAN6Ptex', 'GP4GH', 'GPDDA1', 'MDDEP4pp', 'GPDDA1pp', 'MINOHPtexi', 'MECDPS', 'MLTG1', 'MLTG2', 'MELIBtex', 'MEOHtex', 'MEOHtrpp', 'MEPCT', 'METAT', 'METDabcpp', 'GPDDA3', 'METDtex', 'MLTGY4pp', 'METS', 'METSOX1abcpp', 'METSOX1tex', 'METSOX2abcpp', 'METSOX2tex', 'MMETtex', 'METTRS', 'METabcpp', 'METtex', 'MG2tex', 'MNLptspp', 'MNLtex', 'MNNH', 'MNtex', 'MOADSUx', 'MOAT', 'MI1PP', 'MOAT2', 'MOBDabcpp', 'MOBDtex', 'MOCDS', 'MOCOS', 'MOGDS', 'GPDDA5', 'MOHMT', 'MPTAT', 'GPDDA5pp', 'NACtex', 'NACtpp', 'MPTG2', 'GRTT', 'MPTS', 'MPTSS', 'MSO3abcpp', 'MSO3tex', 'MTAN', 'MTHFR2', 'MTHTHFSs', 'MTRPOX', 'N2Otex', 'N2Otpp', 'GSNt2pp', 'GSNtex', 'OCDCAtexi', 'NAtex', 'NO3t7pp', 'NO3tex', 'NOtex', 'NOtpp', 'GTHOXtex', 'NTD10pp', 'NTD11pp', 'NI2tex', 'NTD12pp', 'NTD1pp', 'NMNtex', 'NTD2pp', 'NTD3pp', 'NTD4pp', 'NTD5pp', 'NNDMBRT', 'NNDPR', 'NTD6pp', 'NTD7pp', 'NO2t2rpp', 'NO2tex', 'NTD8pp', 'NTD9pp', 'NTP11', 'NTP12', 'OCDCEAtexi', 'OCTAtex', 'OCTDPS', 'NTP3pp', 'OGMEACPD', 'GTHRDtex', 'OGMEACPR', 'OGMEACPS', 'OHPBAT', 'OHPHM', 'OMBZLM', 'OMCDC', 'GTPCI', 'GTPCII2', 'OP4ENH', 'OPHBDC', 'OPMEACPD', 'OPMEACPR', 'O16A4COLIPAabctex', 'OPMEACPS', 'O16GLCT2', 'ORNtex', 'O2Stex', 'OROTtex', 'OXCDC', 'GTPtex', 'PEAMNOpp', 'PEAMNtex', 'PERD', 'PETNT161pp', 'PETNT181pp', 'PFK_2', 'PACALDt2rpp', 'PACALDtex', 'PANTS', 'PAPA120pp', 'PAPA140pp', 'PAPA141pp', 'PAPA160pp', 'PAPA161pp', 'PAPA180pp', 'PGLYCP', 'PAPA181pp', 'PDX5PS', 'PRAIi', 'PRAMPC', 'PRATPP', 'PRMICI', 'PROGLYabcpp', 'PHEMEabcpp', 'PHEMEtiex', 'PHETA1', 'PROGLYtex', 'PROTRS', 'PHETRS', 'PHEt2rpp', 'PHEtex', 'PHYTSpp', 'PSCLYSt2pp', 'PSCLYStex', 'PSCVT', 'PSERtex', 'QUIN2tex', 'QUIN2tpp', 'QUINDH', 'QULNS', 'R5PPpp', 'PTA2', 'R5Ptex', 'RBFK', 'RBFSa', 'RBFSb', 'PTPATi', 'RBP4E', 'PTRCtex', 'RHCCE', 'RIBtex', 'RMI', 'RMK', 'RMNtex', 'RMNtpp', 'RMPA', 'PYDAMtex', 'PYDAMtpp', 'PYDXNtex', 'PYDXNtpp', 'PYDXtex', 'PYDXtpp', 'SPMDAT2', 'RZ5PP', 'SPMDtex', 'S2FE2SR', 'SPMS', 'S2FE2SS', 'S2FE2SS2', 'S2FE2ST', 'SPODMpp', 'S4FE4SR', 'S4FE4ST', 'S7PI', 'SUCBZL', 'SUCBZS', 'SARCOX', 'SBTPD', 'SBTptspp', 'SBTtex', 'SCYSDS', 'SDPDS', 'SDPTA', 'SELCYSS', 'SELGTHR', 'SELGTHR2', 'SELGTHR3', 'SELNPS', 'SELR', 'SUCRtex', 'SUCptspp', 'SELtex', 'SULFACabcpp', 'SELtpp', 'SEPHCHCS', 'SULFACtex', 'TAGURr', 'TARTRDtex', 'SERTRS', 'SERTRS2', 'TARTRt7pp', 'TARTRtex', 'TARTt2_3pp', 'TAUDO', 'TAURabcpp', 'TAURtex', 'SHCHCS3', 'TCYNTtex', 'TDPADGAT', 'TDPAGTA', 'TDPDRE', 'TDPDRR', 'TDPGDH', 'TDSK', 'SHCHD2', 'SHCHF', 'SHK3Dr', 'SHKK', 'SHSL1', 'SKMt2pp', 'SKMtex', 'SLNTtex', 'TDSR1', 'TGBPA', 'THDPS', 'SO2tex', 'SO2tpp', 'SO3tex', 'THMDt2pp', 'THMDtex', 'THMabcpp', 'THMtex', 'SPMDAT1', 'TYRTA', 'TYRTRS', 'THRPtex', 'THRTRS', 'TYRt2rpp', 'TYRtex', 'ThDPAT', 'U23GAAT', 'UACGALPpp', 'UACGAMPpp', 'THZPSN3', 'UACGAMtex', 'UACMAMO', 'UAG2E', 'UAGAAT', 'TMAOtex', 'TMAtex', 'TMK', 'UDCPDPS', 'UDCPDPpp', 'UDCPPtppi', 'UDPACGALtex', 'UDPG4E', 'TMPPP', 'UDPGALPpp', 'UDPGALtex', 'UDPGD', 'UDPGDC', 'UDPGLCURtex', 'UDPGPpp', 'UDPGtex', 'UDPKAAT', 'UGLCURPpp', 'TREHpp', 'TREtex', 'UGLT', 'UHGADA', 'TRPTRS', 'TRPt2rpp', 'TRPtex', 'ULA4NFT', 'ULA4Ntppi', 'TSULabcpp', 'TSULtex', 'TTDCAtexi', 'TTDCEAtexi', 'TUNGSabcpp', 'UMPtex', 'UPLA4FNF', 'UPLA4FNT', 'UPP3MT', 'UPP3S', 'UPPDC1', 'TUNGStex', 'TYMtex', 'TYRL', 'TYROXDApp', 'TYRPpp', 'TYRPtex', 'PMDPHT', 'WCOS', 'X5PL3E', 'URIt2pp', 'URItex', 'USHD', 'VALTRS', 'XMPtex', 'PMEACPE', 'XTSNtex', 'XYLI1', 'XYLK', 'XYLK2', 'PNTK', 'XYLUt2pp', 'MDRPD', 'XYLUtex', 'PNTOt4pp', 'MTRI', 'MTRK', 'XYLtex', 'Zn2tex', 'OXGDC2', 'PNTOtex', 'SHCHCS2', 'EX_3hoxpac_e', 'EX_3ntym_e', 'EX_4hoxpac_e', 'EX_6apa_e', 'THZPSN', 'UNK3', 'CLBtex', 'SALCNtex', 'RAFFtex', 'GALAMtex', 'EX_cellb_e', 'EX_galam_e', 'GALAM6PISO', 'EX_lipidA_core_e', 'ACGAL6PISO', '3hoxpactex', 'EX_o6a4colipa_e', 'EX_peng_e', 'PPALtex', 'PPALtpp', '4hoxpactex', 'PPAtex', 'PPBNGS', 'HHEDA', 'PACt1', 'PPCDC', 'PACt', '2DHPACCOAH', '3DHPACCOAH', 'PENGt1', '6APAt1', '3ntymex', '3NTYROXDApp', '4H3NPACALDt2rpp', '4H3NALDD', '4HOXPACDtpp', '4HALDD_1', '34DHPHAtpp', '34DHALDD', 'LIP4Atppi', 'LIPIDAt1ex', 'LIPIDAt2ex', 'PPNCL2', 'PETNLA161pp', 'PETNLA181pp', 'PPND', 'ENLIPIDAt1ex', 'ENLIPIDAt2ex', 'PETNENLA161pp', 'PPNDH', 'PETNENLA181pp', '14DENLIPIDAt1ex', '14DENLIPIDAt2ex', 'LIPAHT3ex', 'LIPAcore', 'LIPIDACOt1ex', 'PPPNDO', 'LIPIDACOt2ex', 'EDTXSA1', 'PPPNt2rpp', 'EDTXSB1', 'LIPAAabcpp', 'LIPABabcpp', 'EDTXSF1', 'EDTXSF120', 'EX_raffin_e', 'EDTXSF140', 'PPPNtex', 'EDTXSF141', 'EDTXSF160', 'EDTXSF161', 'EDTXSF180', 'EX_salcn_e', 'EDTXSF181', 'PPTHpp', 'EDTXS_core', 'LIPAt1ex', 'PPTtex', 'LIPAt2ex', 'ENLIPAt1ex', 'AOXSr', 'ENLIPAt2ex', 'HEPTA1', 'HEPTA2', 'HEPKA1', 'HEPTA3', 'HEPKA2', 'BTS4', 'DHPTDCs', 'DM_4hba_c', 'DM_hmfurn_c', 'GLCTRA1', 'GLCR1TRA2', 'HEPTB1', 'HEPTB2', 'HEPKB1', 'HEPTB3', 'HEPKB2', 'GLCTRB1', 'GLCR1TRB2', 'COLIPABabcpp', 'EDTXSCOF1', 'EDTXSCOF120', 'EDTXSCOF140', 'EDTXSCOF141', 'EDTXSCOF160', 'EDTXSCOF161', 'EDTXSCOF180', 'EDTXSCOF181', 'EDTXSCOF', 'O6MANT1', 'O6MANT2', 'O6GALT1', 'O6GLCT1', 'DARBtex', 'O6AP1pp', 'O6AP2pp', 'O6AP3pp', 'O6A4Lpp', 'EX_arab__D_e', 'COLIPAt1ex', 'COLIPAt2ex', 'O6A4COLIPAt1ex', 'DHPDO', 'O6A4COLIPAt2ex', 'ECA4COLIPAt1ex', 'ECA4COLIPAt2ex', 'ACOLIPAt1ex', 'ACOLIPAt2ex', 'CLIPAt1ex', 'CLIPAt2ex', 'LIPIDIIFLIP', 'PUTAM', 'ARABDI', 'BDH', '34HPPOR', 'ALPHNH', 'CMLBL', 'CHOLSH', 'CHDLDH', 'DHXAN', 'AMID', 'ARABD', 'IDTDH', 'LYSAM', 'MAL6PG', 'MPL', 'AMID5', 'APRTO2_1', '5HOXINOXDA_1', '41R2A1H12BOOX_1', '41R1H2MAE12BOOX', 'MAOLNOR', 'DURAD2', 'ASNO', 'TRYPTAOX_1', 'SBTD_D2', 'HPA3MOFAD', 'TARTH', 'DIEHLAC', '42A12BOOX', 'AMID3', 'SUCP', 'LTARTDH', 'UAG4Ei', 'UGCIAMH']\n"
     ]
    }
   ],
   "source": [
    "int_reactions= list()\n",
    "i= -1\n",
    "n= 0\n",
    "r = a.reactions[0]\n",
    "r_id = r.id\n",
    "zero= list()\n",
    "one= list()\n",
    "one_at_zero= list()\n",
    "\n",
    "for r in a.reactions:  #finds reactions that have one feasible value at flux=0 or for another flux\n",
    "    i= i+1\n",
    "    r = a.reactions[i]\n",
    "    r_id = r.id\n",
    "\n",
    "    csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "    v= len(csvFile[\"Biomass\"])-csvFile[\"Biomass\"].isna().sum()\n",
    "    n= int((len(csvFile)-1)/2)\n",
    "\n",
    "    flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "    if v == 1 and csvFile.iloc[n,  2] != flt:\n",
    "        one.append(r_id)\n",
    "    elif v == 0:\n",
    "        zero.append(r_id)\n",
    "        \n",
    "    if v == 1 and csvFile.iloc[n,  2] == flt:\n",
    "        one_at_zero.append(r_id)\n",
    "\n",
    "print(one)\n",
    "print(zero)\n",
    "print(one_at_zero)\n",
    "\n",
    "D= pd.DataFrame (one, columns = ['1 feasible value'])\n",
    "D_at_zero= pd.DataFrame (one_at_zero, columns = ['1 feasible value_at_zero'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adequate-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "r = a.reactions[0]\n",
    "l2= list()\n",
    "l3= list()\n",
    "\n",
    "for r in a.reactions:            #separates reactions that have biomass values for positive and negative flux values\n",
    "    \n",
    "    r = a.reactions[i]\n",
    "    r_id = r.id\n",
    "    csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "    i3= int(((len(csvFile)-1)/2)+1)\n",
    "\n",
    "    while i3< len(csvFile):\n",
    "        inf= csvFile.iloc[i3,  2]\n",
    "        flt= float(csvFile.iloc[i3,  2])\n",
    "    \n",
    "        if csvFile.iloc[i3,  2] == flt and r_id not in l2:\n",
    "            l2.append(r_id)     #l2 contains reactions that have biomass values for positive flux values\n",
    "        i3= i3+1\n",
    "    \n",
    "    i4= 0\n",
    "    \n",
    "    while i4< int(((len(csvFile)-1)/2)):\n",
    "        inf= csvFile.iloc[i4,  2]\n",
    "        flt= float(csvFile.iloc[i4,  2])\n",
    "    \n",
    "        if csvFile.iloc[i4,  2] == flt and r_id not in l3:\n",
    "            l3.append(r_id)    #l3 contains reactions that have biomass values for negative flux values\n",
    "        i4= i4+1\n",
    "\n",
    "    i= i+1\n",
    "\n",
    "D1= pd.DataFrame (l2, columns = ['Reaction names'])\n",
    "D2= pd.DataFrame (l3, columns = ['Reaction names'])\n",
    "b= D1.iloc[:, 0]\n",
    "c= D2.iloc[:, 0]\n",
    "\n",
    "union = pd.Series(np.union1d(b, c))\n",
    "intersect = pd.Series(np.intersect1d(b, c))\n",
    "bigb2= union[~union.isin(intersect)]\n",
    "\n",
    "D3= pd.DataFrame (bigb2, columns = ['Reaction names'])\n",
    "D3\n",
    "D3.to_csv(\"res2.csv\")      #contains reactions that have biomass values for either positive or negative flux values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "indecr_and_stable_above_zero= list()\n",
    "diff_indecr_above_zero= list()\n",
    "flat_above_zero= list()\n",
    "one_to_three_data_point_above_zero= list()\n",
    "r_id = a.reactions[0]\n",
    "\n",
    "\n",
    "for r_id in a.reactions:    #separates everything that has an increasing/decreasing pattern from everything that has a saturating pattern and everything that is flat above zero\n",
    "    l= list()\n",
    "    n=0\n",
    "    n2=0\n",
    "    count=0\n",
    "    r = a.reactions[i]\n",
    "    r_id = r.id\n",
    "    csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "    while n < len(csvFile):\n",
    "        inf= csvFile.iloc[n,  2]\n",
    "        flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "        if csvFile.iloc[n,  2] == flt:\n",
    "            l.append(csvFile.iloc[n,  2])\n",
    "        n= n+1\n",
    "\n",
    "    d= pd.DataFrame (l, columns = ['Biomass'])\n",
    "    d.Biomass = d.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "    my_series = d['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "    if (len(d)> 30 or len(d)==30) and r_id in l2 and r_id not in l3:\n",
    "        \n",
    "        while n2 < len(d):\n",
    "\n",
    "            if d.iloc[n2,  0] > max(d[\"Biomass\"])-0.01 and d.iloc[n2,  0] < max(d[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        if count> 0.03*len(d) and count< 0.97*len(d):\n",
    "            indecr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "        elif count> 0.97*len(d):\n",
    "            flat_above_zero.append(r_id)\n",
    "        \n",
    "        else:\n",
    "            diff_indecr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "    if len(d)> 1 and len(d)<30  and r_id in l2 and r_id not in l3:\n",
    "        \n",
    "        while n2 < len(d):\n",
    "\n",
    "            if d.iloc[n2,  0] > max(d[\"Biomass\"])-0.01 and d.iloc[n2,  0] < max(d[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        if count> 1 and count< len(d)-1:\n",
    "            indecr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "        elif count> 1 and len(d) < 3:\n",
    "            flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif count> 2 and len(d) < 6:\n",
    "            flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif count> len(d)-3 and len(d)> 5:\n",
    "            flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif len(d)<4:\n",
    "            one_to_three_data_point_above_zero.append(r_id)\n",
    "        \n",
    "        else:\n",
    "            diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "    i= i+1\n",
    "\n",
    "flat_above_zero\n",
    "diff_indecr_above_zero\n",
    "indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_above_zero)+len(diff_indecr_above_zero)+len(indecr_and_stable_above_zero)+len(one_to_three_data_point_above_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-agreement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i= 0\n",
    "indecr_and_stable_below_zero= list()\n",
    "diff_indecr_below_zero= list()\n",
    "flat_below_zero= list()\n",
    "one_to_three_data_point_below_zero= list()\n",
    "r_id = a.reactions[0]\n",
    "\n",
    "\n",
    "for r_id in a.reactions:    #separates everything that has an increasing/decreasing pattern from everything that has a saturating pattern and everything that is flat below zero\n",
    "    l= list()\n",
    "    n=0\n",
    "    n2=0\n",
    "    count=0\n",
    "    r = a.reactions[i]\n",
    "    r_id = r.id\n",
    "    csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "    while n < len(csvFile):\n",
    "        inf= csvFile.iloc[n,  2]\n",
    "        flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "        if csvFile.iloc[n,  2] == flt:\n",
    "            l.append(csvFile.iloc[n,  2])\n",
    "        n= n+1\n",
    "\n",
    "    d= pd.DataFrame (l, columns = ['Biomass'])\n",
    "    d.Biomass = d.Biomass.round(2)\n",
    "    \n",
    "    my_series = d['Biomass'].squeeze()\n",
    "    \n",
    "\n",
    "    if (len(d)> 30 or len(d)==30) and r_id in l3 and r_id not in l2:\n",
    "        \n",
    "        while n2 < len(d):\n",
    "\n",
    "            if d.iloc[n2,  0] > max(d[\"Biomass\"])-0.01 and d.iloc[n2,  0] < max(d[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        if count> 0.03*len(d) and count< 0.97*len(d):\n",
    "            indecr_and_stable_below_zero.append(r_id)\n",
    "\n",
    "        elif count> 0.97*len(d):\n",
    "            flat_below_zero.append(r_id)\n",
    "        \n",
    "        else:\n",
    "            diff_indecr_below_zero.append(r_id)\n",
    "\n",
    "    \n",
    "    if len(d)> 1 and len(d)<30  and r_id in l3 and r_id not in l2:\n",
    "        \n",
    "        while n2 < len(d):\n",
    "\n",
    "            if d.iloc[n2,  0] > max(d[\"Biomass\"])-0.01 and d.iloc[n2,  0] < max(d[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        if count> 1 and count< len(d)-1:\n",
    "            indecr_and_stable_below_zero.append(r_id)\n",
    "\n",
    "        elif count> 1 and len(d) < 3:\n",
    "            flat_below_zero.append(r_id)\n",
    "        \n",
    "        elif count> 2 and len(d) < 6:\n",
    "            flat_below_zero.append(r_id)\n",
    "        \n",
    "        elif count> len(d)-3 and len(d)> 5:\n",
    "            flat_below_zero.append(r_id)\n",
    "        \n",
    "        elif len(d)<4:\n",
    "            one_to_three_data_point_below_zero.append(r_id)\n",
    "        \n",
    "        else:\n",
    "            diff_indecr_below_zero.append(r_id)\n",
    "    \n",
    "    i= i+1\n",
    "\n",
    "flat_below_zero\n",
    "diff_indecr_below_zero\n",
    "indecr_and_stable_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "color-angel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TMPK',\n",
       " 'AGPAT161',\n",
       " 'UAGDP',\n",
       " 'ACPPAT160',\n",
       " 'MCOATA',\n",
       " 'ACODA',\n",
       " 'DASYN160',\n",
       " 'ICDHyr',\n",
       " 'ADSS',\n",
       " 'NDPK2',\n",
       " 'NH4tex',\n",
       " 'PSD161',\n",
       " 'ACGS',\n",
       " 'O2tpp',\n",
       " 'P5CR',\n",
       " 'HSK',\n",
       " 'ACCOAC',\n",
       " 'PMPK',\n",
       " 'ALAALAr',\n",
       " 'CYSS',\n",
       " 'PSSA161',\n",
       " 'G1PACT',\n",
       " 'CTPS2',\n",
       " 'THRS',\n",
       " 'NADK',\n",
       " 'PE160abcpp',\n",
       " 'ASPK',\n",
       " 'ARGSS',\n",
       " 'ADSL1r',\n",
       " 'DASYN161',\n",
       " '3OAS140',\n",
       " 'APG3PAT160',\n",
       " 'GF6PTA',\n",
       " 'ACPPAT161',\n",
       " 'UMPK',\n",
       " 'OCBT',\n",
       " '3OAR140',\n",
       " 'PE161abcpp',\n",
       " 'ACGK',\n",
       " 'DTMPK',\n",
       " 'GK1',\n",
       " 'G5SADs',\n",
       " 'AGPAT160',\n",
       " 'GLNS',\n",
       " 'ARGSL',\n",
       " 'HCO3E',\n",
       " 'SERAT',\n",
       " 'NNATr',\n",
       " 'THRD_L',\n",
       " 'NADS1',\n",
       " 'APG3PAT161',\n",
       " 'COBALT2tpp',\n",
       " 'NDPK4',\n",
       " 'PSD160',\n",
       " 'CS',\n",
       " 'PSSA160',\n",
       " 'ACONTb',\n",
       " 'GMPS2',\n",
       " 'ALAR',\n",
       " 'ACONTa',\n",
       " 'CU2tpp']"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_above_zero= list()\n",
    "mon_decr_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_above_zero)> 0:\n",
    "    \n",
    "    for r_id in diff_indecr_above_zero:                    #this code separates reactions with an increasing and stable trend from reactions with a decreasing and stable trend above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = diff_indecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        type(my_series)\n",
    "\n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_above_zero)\n",
    "set2= set(mon_decr_above_zero)\n",
    "set3= set(mon_incr_above_zero)\n",
    "inANDdecr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "legitimate-delaware",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TMPK',\n",
       " 'AGPAT161',\n",
       " 'UAGDP',\n",
       " 'ACPPAT160',\n",
       " 'MCOATA',\n",
       " 'ACODA',\n",
       " 'DASYN160',\n",
       " 'ICDHyr',\n",
       " 'ADSS',\n",
       " 'NDPK2',\n",
       " 'NH4tex',\n",
       " 'PSD161',\n",
       " 'ACGS',\n",
       " 'P5CR',\n",
       " 'HSK',\n",
       " 'ACCOAC',\n",
       " 'PMPK',\n",
       " 'ALAALAr',\n",
       " 'CYSS',\n",
       " 'PSSA161',\n",
       " 'G1PACT',\n",
       " 'CTPS2',\n",
       " 'THRS',\n",
       " 'NADK',\n",
       " 'PE160abcpp',\n",
       " 'ASPK',\n",
       " 'ARGSS',\n",
       " 'ADSL1r',\n",
       " 'DASYN161',\n",
       " '3OAS140',\n",
       " 'APG3PAT160',\n",
       " 'GF6PTA',\n",
       " 'ACPPAT161',\n",
       " 'UMPK',\n",
       " 'OCBT',\n",
       " '3OAR140',\n",
       " 'PE161abcpp',\n",
       " 'ACGK',\n",
       " 'DTMPK',\n",
       " 'GK1',\n",
       " 'G5SADs',\n",
       " 'AGPAT160',\n",
       " 'GLNS',\n",
       " 'ARGSL',\n",
       " 'HCO3E',\n",
       " 'SERAT',\n",
       " 'NNATr',\n",
       " 'THRD_L',\n",
       " 'NADS1',\n",
       " 'APG3PAT161',\n",
       " 'COBALT2tpp',\n",
       " 'NDPK4',\n",
       " 'PSD160',\n",
       " 'CS',\n",
       " 'PSSA160',\n",
       " 'ACONTb',\n",
       " 'GMPS2',\n",
       " 'ALAR',\n",
       " 'ACONTa',\n",
       " 'CU2tpp']"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= list()\n",
    "w2= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_above_zero)> 0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_above_zero):        #this code finds reactions that are not truly both increasing and decreasing and stable above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2]<max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w2.append(r_id)\n",
    "\n",
    "        i2= i2+1\n",
    "\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "opposite-continent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w, w2))\n",
    "unclassified_above_zero = pd.Series(np.intersect1d(w, w2))\n",
    "\n",
    "set1= set(w)\n",
    "set2= set(unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w= list(set3)\n",
    "\n",
    "set1= set(w2)\n",
    "set2= set(unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w2= list(set3)\n",
    "\n",
    "unclassified_above_zero= list(unclassified_above_zero)\n",
    "unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "informal-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(inANDdecr_above_zero)\n",
    "set2= set(w)\n",
    "set3= set(unclassified_above_zero)\n",
    "set4= set1-set2-set3\n",
    "inANDdecr_above_zero= list(set4)\n",
    "\n",
    "mon_decr_above_zero= list(mon_decr_above_zero) + list(w)\n",
    "\n",
    "\n",
    "set1= set(inANDdecr_above_zero)\n",
    "set2= set(w2)\n",
    "set3= set1-set2\n",
    "inANDdecr_above_zero= list(set3)\n",
    "\n",
    "mon_incr_above_zero= list(mon_incr_above_zero) + list(w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "great-tracker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_galt_e',\n",
       " 'EX_cgly_e',\n",
       " 'RPI',\n",
       " 'EX_sbt__D_e',\n",
       " 'EX_gal_e',\n",
       " 'ACOTA',\n",
       " 'EX_malt_e',\n",
       " 'EX_butso3_e',\n",
       " 'EX_hdcea_e',\n",
       " 'EX_nh4_e',\n",
       " 'EX_fum_e',\n",
       " 'OMPHHX3',\n",
       " 'EX_dca_e',\n",
       " 'EX_udpglcur_e',\n",
       " 'EX_melib_e',\n",
       " 'EX_hxa_e',\n",
       " 'EX_ddca_e',\n",
       " 'EX_arab__L_e',\n",
       " 'EX_ttdcea_e',\n",
       " 'EX_galur_e',\n",
       " 'EX_pppn_e',\n",
       " 'ASPTA',\n",
       " 'EX_progly_e',\n",
       " 'EX_LalaLglu_e',\n",
       " 'EX_all__D_e',\n",
       " 'EX_ptrc_e',\n",
       " 'EX_acmum_e',\n",
       " 'EX_sucr_e',\n",
       " 'EX_LalaDgluMdapDala_e',\n",
       " 'EX_acmana_e',\n",
       " 'EX_ocdca_e',\n",
       " 'AGPR',\n",
       " 'EX_LalaDglu_e',\n",
       " 'EX_tartr__L_e',\n",
       " 'EX_xyl__D_e',\n",
       " 'EX_23dappa_e',\n",
       " 'EX_gthrd_e',\n",
       " 'OPHHX3',\n",
       " 'EX_lyx__L_e',\n",
       " 'EX_xylu__L_e',\n",
       " 'EX_fe3dcit_e',\n",
       " 'G3PD2',\n",
       " 'EX_26dap__M_e',\n",
       " 'EX_udpacgal_e',\n",
       " 'EX_3hpppn_e',\n",
       " 'EX_ocdcea_e',\n",
       " 'HSDy',\n",
       " 'EX_LalaDgluMdap_e',\n",
       " 'EX_23ccmp_e',\n",
       " 'EX_mnl_e',\n",
       " 'EX_anhgm_e',\n",
       " 'EX_chtbs_e',\n",
       " 'EX_acgam_e',\n",
       " 'EX_tartr__D_e',\n",
       " 'ASAD',\n",
       " 'EX_rib__D_e',\n",
       " 'EX_ascb__L_e',\n",
       " 'EX_octa_e',\n",
       " 'PGAMT',\n",
       " 'OMMBLHX3',\n",
       " 'EX_but_e',\n",
       " 'EX_acnam_e',\n",
       " 'EX_ethso3_e',\n",
       " 'EX_galct__D_e',\n",
       " 'EX_3hcinnm_e',\n",
       " 'EX_hdca_e',\n",
       " 'EX_glcr_e',\n",
       " 'EX_ttdca_e']"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_below_zero= list()\n",
    "mon_decr_below_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero)> 0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero:                    #this code separates reactions with an increasing and stable trend from reactions with a decreasing and stable trend above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = diff_indecr_below_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        type(my_series)\n",
    "\n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero)\n",
    "set2= set(mon_decr_below_zero)\n",
    "set3= set(mon_incr_below_zero)\n",
    "inANDdecr_below_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "bright-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= list()\n",
    "w2= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero)> 0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero):        #this code finds reactions that are not truly both increasing and decreasing and stable above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_below_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w2.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2+1\n",
    "\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "neither-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w, w2))\n",
    "unclassified_below_zero = pd.Series(np.intersect1d(w, w2))\n",
    "\n",
    "set1= set(w)\n",
    "set2= set(unclassified_below_zero)\n",
    "set3= set1-set2\n",
    "w= list(set3)\n",
    "\n",
    "set1= set(w2)\n",
    "set2= set(unclassified_below_zero)\n",
    "set3= set1-set2\n",
    "w2= list(set3)\n",
    "\n",
    "unclassified_below_zero= list(unclassified_below_zero)\n",
    "unclassified_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "agricultural-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(inANDdecr_below_zero)\n",
    "set2= set(w)\n",
    "set3= set(unclassified_below_zero)\n",
    "set4= set1-set2-set3\n",
    "inANDdecr_below_zero= list(set4)\n",
    "\n",
    "mon_decr_below_zero= list(mon_decr_below_zero) + list(w)\n",
    "\n",
    "\n",
    "set1= set(inANDdecr_below_zero)\n",
    "set2= set(w2)\n",
    "set3= set1-set2\n",
    "inANDdecr_below_zero= list(set3)\n",
    "\n",
    "mon_incr_below_zero= list(mon_incr_below_zero) + list(w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "mysterious-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NH4tpp', 'O2tex']"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_and_stable_above_zero= list()\n",
    "mon_decr_and_stable_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_above_zero)> 0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_above_zero:                    #this code separates reactions with an increasing and stable trend from reactions with a decreasing and stable trend above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        type(my_series)\n",
    "\n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_above_zero)\n",
    "set2= set(mon_decr_and_stable_above_zero)\n",
    "set3= set(mon_incr_and_stable_above_zero)\n",
    "inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "attached-cycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= list()\n",
    "w2= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_above_zero)> 0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_above_zero):        #this code finds reactions that are not truly both increasing and decreasing and stable above zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w2.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2+1\n",
    "\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "transsexual-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w, w2))\n",
    "unclassified_above_zero2 = pd.Series(np.intersect1d(w, w2))\n",
    "\n",
    "set1= set(w)\n",
    "set2= set(unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w= list(set3)\n",
    "\n",
    "set1= set(w2)\n",
    "set2= set(unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w2= list(set3)\n",
    "\n",
    "unclassified_above_zero= list(unclassified_above_zero2)+list(unclassified_above_zero)\n",
    "unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "accepted-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(inANDdecr_and_stable_above_zero)\n",
    "set2= set(w)\n",
    "set3= set(unclassified_above_zero2)\n",
    "set4= set1-set2-set3\n",
    "inANDdecr_and_stable_above_zero= list(set4)\n",
    "\n",
    "mon_decr_and_stable_above_zero= list(mon_decr_and_stable_above_zero) + list(w)\n",
    "\n",
    "\n",
    "set1= set(inANDdecr_and_stable_above_zero)\n",
    "set2= set(w2)\n",
    "set3= set1-set2\n",
    "inANDdecr_and_stable_above_zero= list(set3)\n",
    "\n",
    "mon_incr_and_stable_above_zero= list(mon_incr_and_stable_above_zero) + list(w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "prospective-criticism",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NTRIR4pp',\n",
       " 'EX_h2_e',\n",
       " 'EX_gam_e',\n",
       " 'EX_manglyc_e',\n",
       " 'NTRIR3pp',\n",
       " 'NO3R1bpp',\n",
       " 'EX_cynt_e',\n",
       " 'EX_uacgam_e',\n",
       " 'EX_agm_e',\n",
       " 'EX_udpg_e',\n",
       " 'EX_ppal_e',\n",
       " 'NTRIR2x',\n",
       " 'EX_glc__D_e',\n",
       " 'EX_man_e',\n",
       " 'EX_ppa_e',\n",
       " 'EX_o2_e',\n",
       " 'EX_udpgal_e',\n",
       " 'EX_fru_e',\n",
       " 'PPPGO']"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_and_stable_below_zero= list()\n",
    "mon_decr_and_stable_below_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero)> 0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero:                    #this code separates reactions with an increasing and stable trend from reactions with a decreasing and stable trend below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = indecr_and_stable_below_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        type(my_series)\n",
    "\n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_below_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_below_zero.append(r_id)\n",
    "\n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero)\n",
    "set2= set(mon_decr_and_stable_below_zero)\n",
    "set3= set(mon_incr_and_stable_below_zero)\n",
    "inANDdecr_and_stable_below_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "operating-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NTRIR4pp', 'PPPGO']"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero):       #this code finds reactions that are not truly both increasing and decreasing and stable below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_below_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "nominated-resistance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero= list(unclassified_below_zero2)+list(unclassified_below_zero)\n",
    "unclassified_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "textile-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(inANDdecr_and_stable_below_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero2)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero= list(set5)\n",
    "\n",
    "mon_decr_and_stable_below_zero= list(mon_decr_and_stable_below_zero) + list(w3)\n",
    "mon_incr_and_stable_below_zero= list(mon_incr_and_stable_below_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "tender-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_glcn_e',\n",
       " 'EX_glu__L_e',\n",
       " 'EX_gly_e',\n",
       " 'EX_glyald_e',\n",
       " 'EX_glyc_e',\n",
       " 'EX_glyc__R_e',\n",
       " 'EX_glyc3p_e',\n",
       " 'EX_glyclt_e',\n",
       " 'EX_gua_e',\n",
       " 'EX_h_e',\n",
       " 'EX_12ppd__S_e',\n",
       " 'EX_4abut_e',\n",
       " 'EX_hxan_e',\n",
       " 'EX_5dglcn_e',\n",
       " 'EX_cys__L_e',\n",
       " 'EX_ac_e',\n",
       " 'EX_idon__L_e',\n",
       " 'EX_acald_e',\n",
       " 'EX_lac__D_e',\n",
       " 'EX_lac__L_e',\n",
       " 'EX_ade_e',\n",
       " 'EX_akg_e',\n",
       " 'EX_ala__D_e',\n",
       " 'EX_ala__L_e',\n",
       " 'EX_mal__L_e',\n",
       " 'EX_alltn_e',\n",
       " 'EX_asn__L_e',\n",
       " 'EX_asp__L_e',\n",
       " 'EX_dha_e',\n",
       " 'EX_xan_e',\n",
       " 'EX_pro__L_e',\n",
       " 'EX_pyr_e',\n",
       " 'EX_ser__L_e',\n",
       " 'EX_etha_e',\n",
       " 'EX_succ_e',\n",
       " 'EX_etoh_e',\n",
       " 'EX_thr__L_e',\n",
       " 'EX_fe2_e',\n",
       " 'EX_for_e',\n",
       " 'ACACT8r_copy1',\n",
       " 'ACKr',\n",
       " 'ALAALAD',\n",
       " 'ADA',\n",
       " 'ADD',\n",
       " 'ALDD2x',\n",
       " 'ADNK1',\n",
       " 'ADNUC',\n",
       " 'ALDD2y',\n",
       " 'ADPT',\n",
       " 'AMPN',\n",
       " 'ASPt2pp_copy2',\n",
       " 'ATPM',\n",
       " 'CAT',\n",
       " 'CBPS',\n",
       " 'CD2abcpp',\n",
       " 'COBALT2abcpp',\n",
       " 'DADA',\n",
       " 'CTECOAI6_copy1',\n",
       " 'CTECOAI7_copy1',\n",
       " 'CTECOAI8_copy1',\n",
       " 'CYSabc2pp',\n",
       " 'CYTBD2pp',\n",
       " 'CYTBDpp',\n",
       " 'CYTBO3_4pp',\n",
       " 'DHAPT',\n",
       " 'DAAD',\n",
       " 'DHORD2',\n",
       " 'DHORDfum',\n",
       " 'ARGDC',\n",
       " 'ARGDCpp',\n",
       " 'EAR100x',\n",
       " 'EAR100y',\n",
       " 'EAR120x',\n",
       " 'EAR120y',\n",
       " 'ARGabcpp',\n",
       " 'EAR121x',\n",
       " 'EAR121y',\n",
       " 'EAR140x',\n",
       " 'EAR140y',\n",
       " 'EAR141x',\n",
       " 'EAR141y',\n",
       " 'EAR160x',\n",
       " 'EAR160y',\n",
       " 'EAR161x',\n",
       " 'F6PP',\n",
       " 'EAR161y',\n",
       " 'EAR180x',\n",
       " 'EAR180y',\n",
       " 'EAR181x',\n",
       " 'FA120ACPHi',\n",
       " 'FA140ACPHi',\n",
       " 'FA141ACPHi',\n",
       " 'FA160ACPHi',\n",
       " 'FA161ACPHi',\n",
       " 'EAR181y',\n",
       " 'FADRx',\n",
       " 'FADRx2',\n",
       " 'FBP',\n",
       " 'FDH4pp',\n",
       " 'ASNN',\n",
       " 'FACOAL60t2pp',\n",
       " 'ASNNpp',\n",
       " 'ASNS1',\n",
       " 'FE2abcpp',\n",
       " 'FLVR',\n",
       " 'FLVRx',\n",
       " 'FMNRx',\n",
       " 'FMNRx2',\n",
       " 'FE3tex',\n",
       " 'FTHFLi',\n",
       " 'G3PD5',\n",
       " 'G3PD6',\n",
       " 'G3PD7',\n",
       " 'G6PP',\n",
       " 'GLCabcpp',\n",
       " 'GLCptspp',\n",
       " 'GLCt2pp',\n",
       " 'GLCtex_copy1',\n",
       " 'GLUDy',\n",
       " 'GLUN',\n",
       " 'GART',\n",
       " 'GDPMNP',\n",
       " 'GLUSy',\n",
       " 'GLUt2rpp',\n",
       " 'GLYCK',\n",
       " 'GLYCK2',\n",
       " 'GLYC3Pabcpp',\n",
       " 'GLYC3Pt6pp',\n",
       " 'H2Otex',\n",
       " 'GLYCLTDx',\n",
       " 'H2Otpp',\n",
       " 'H2SO',\n",
       " 'GLYCLTDy',\n",
       " 'HXCT',\n",
       " 'HXPRT',\n",
       " 'GLYCTO2',\n",
       " 'IDOND',\n",
       " 'HEX1',\n",
       " 'HEX7',\n",
       " 'GLYK',\n",
       " 'INSH',\n",
       " 'INSK',\n",
       " 'GLYOX3',\n",
       " 'Kabcpp',\n",
       " 'L_LACD2_copy1',\n",
       " 'L_LACD3_copy1',\n",
       " 'LALDO2x',\n",
       " 'LDH_D2',\n",
       " 'LYSabcpp',\n",
       " 'MALt2_3pp',\n",
       " 'MDDCP3pp',\n",
       " 'MDH2',\n",
       " 'MDH3',\n",
       " 'ME1',\n",
       " 'ME2',\n",
       " 'MLDCP2App',\n",
       " 'MLTG3',\n",
       " 'MLTG4',\n",
       " 'MLTG5',\n",
       " 'MMM',\n",
       " 'MN6PP',\n",
       " 'MG2uabcpp',\n",
       " 'MICITDr_copy1',\n",
       " 'MOX',\n",
       " 'NADH10',\n",
       " 'NADH16pp',\n",
       " 'NADH17pp',\n",
       " 'NADH18pp',\n",
       " 'NADH5',\n",
       " 'NADH9',\n",
       " 'NADPHQR2',\n",
       " 'GSNK',\n",
       " 'NADPHQR3',\n",
       " 'NADPHQR4',\n",
       " 'NI2abcpp',\n",
       " 'GTHPi',\n",
       " 'NI2uabcpp',\n",
       " 'NTD7',\n",
       " 'NTD8',\n",
       " 'NTD9',\n",
       " 'NTP1',\n",
       " 'NTP10',\n",
       " 'NTP3',\n",
       " 'NTP5',\n",
       " 'NTPP1',\n",
       " 'NTPP2',\n",
       " 'NTPP3',\n",
       " 'NTPP4',\n",
       " 'NTPP5',\n",
       " 'NTPP6',\n",
       " 'NTPP7',\n",
       " 'NTPP8',\n",
       " 'NTPTP1',\n",
       " 'NTPTP2',\n",
       " 'GTPDPDP',\n",
       " 'ORNabcpp',\n",
       " 'OAADC',\n",
       " 'PFK',\n",
       " 'PFK_3',\n",
       " 'GUAPRT',\n",
       " 'PIt2rpp',\n",
       " 'PRPPS',\n",
       " 'R5PP',\n",
       " 'PTRCabcpp',\n",
       " 'RNTR1c2',\n",
       " 'RNTR2c2',\n",
       " 'RNTR3c2',\n",
       " 'RNTR4c2',\n",
       " 'SSALx',\n",
       " 'SSALy',\n",
       " 'SUCCt2_3pp',\n",
       " 'SUCOAS',\n",
       " 'SERD_D',\n",
       " 'SERD_L',\n",
       " 'SULabcpp',\n",
       " 'THIORDXi',\n",
       " 'SO4t2pp',\n",
       " 'THRA',\n",
       " 'THRD',\n",
       " 'THRabcpp',\n",
       " 'TRPS2',\n",
       " 'TRSARr',\n",
       " 'UPPRT',\n",
       " 'URIH',\n",
       " 'URIK2',\n",
       " 'XTSNH_copy1',\n",
       " 'L_LACD3_copy2',\n",
       " 'MMM2',\n",
       " 'ZN2abcpp',\n",
       " 'ZNabcpp',\n",
       " 'POR5',\n",
       " 'POX',\n",
       " 'PPA',\n",
       " 'PPA2',\n",
       " 'PPK',\n",
       " 'PPM',\n",
       " 'L_LACD2_copy2',\n",
       " 'XTSNH_copy2']"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i= 0\n",
    "over_below_zero_and_under_above_zero= list()\n",
    "under_below_zero_and_over_above_zero= list()\n",
    "over_below_zero_and_over_above_zero= list()\n",
    "under_below_zero_and_under_above_zero= list()\n",
    "r_id = a.reactions[0]\n",
    "\n",
    "for r_id in a.reactions:    #separates reactions based on whether they have less than 30 or not values both in the above and the below zero interval\n",
    "    l= list()\n",
    "    n=0\n",
    "    n2=0\n",
    "    count=0\n",
    "    count2=0\n",
    "    r = a.reactions[i]\n",
    "    r_id = r.id\n",
    "    csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "    while n < int(((len(csvFile)-1)/2)+1):\n",
    "        inf= csvFile.iloc[n,  2]\n",
    "        flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "        if csvFile.iloc[n,  2] == flt:\n",
    "            l.append(csvFile.iloc[n,  2])\n",
    "        n= n+1\n",
    "\n",
    "    csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "    csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "    n= int((len(csvFile)-1)/2)\n",
    "    l4= list()\n",
    "    \n",
    "    while n < len(csvFile):\n",
    "        inf= csvFile.iloc[n,  2]\n",
    "        flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "        if csvFile.iloc[n,  2] == flt:\n",
    "            l4.append(csvFile.iloc[n,  2])\n",
    "        n= n+1\n",
    "\n",
    "    csvFile3= pd.DataFrame (l4, columns = ['Biomass'])\n",
    "    csvFile3.Biomass = csvFile3.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "    my_series = csvFile2['Biomass'].squeeze()\n",
    "    my_series2 = csvFile3['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "    if (len(csvFile2)>30 or len(csvFile2)==30) and len(csvFile3)< 30 and r_id in l3 and r_id in l2:\n",
    "        \n",
    "        over_below_zero_and_under_above_zero.append(r_id)\n",
    "        \n",
    "    if len(csvFile2)<30 and (len(csvFile3)> 30 or len(csvFile3)==30) and r_id in l3 and r_id in l2:\n",
    "    \n",
    "        under_below_zero_and_over_above_zero.append(r_id)\n",
    "    \n",
    "    if (len(csvFile2)>30 or len(csvFile2)==30) and (len(csvFile3)> 30 or len(csvFile3)==30) and r_id in l3 and r_id in l2:\n",
    "    \n",
    "        over_below_zero_and_over_above_zero.append(r_id)\n",
    "        \n",
    "    if len(csvFile2)<30 and len(csvFile3)< 30 and r_id in l3 and r_id in l2:\n",
    "    \n",
    "        under_below_zero_and_under_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    i= i+1\n",
    "    \n",
    "over_below_zero_and_under_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "developed-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NADH16pp', 'NADH17pp', 'NADH18pp']"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i= 0\n",
    "flat_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "diff_indecr_below_zero_and_diff_indecr_above_zero= list()\n",
    "rest_both_positive_and_negative= list()\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_flat_above_zero= list()\n",
    "flat_below_zero_and_flat_above_zero= list()\n",
    "diff_indecr_below_zero_and_flat_above_zero= list()\n",
    "flat_below_zero_and_diff_indecr_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_flat_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_diff_indecr_above_zero= list()\n",
    "flat_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "diff_indecr_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_diff_indecr_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "flat_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "diff_indecr_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "\n",
    "if len(over_below_zero_and_under_above_zero)> 0:\n",
    "\n",
    "    for r_id in over_below_zero_and_under_above_zero:    #separates over_below_zero_and_under_above_zero reactions in more specific subcategories\n",
    "    \n",
    "        l= list()\n",
    "        n=0\n",
    "        n2=0\n",
    "        count=0\n",
    "        count2=0\n",
    "        r_id = over_below_zero_and_under_above_zero[i]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "        while n < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        n= int((len(csvFile)-1)/2)\n",
    "        l4= list()\n",
    "    \n",
    "        while n < len(csvFile):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l4.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile3= pd.DataFrame (l4, columns = ['Biomass'])\n",
    "        csvFile3.Biomass = csvFile3.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        my_series2 = csvFile3['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "        while n2 < len(csvFile2):\n",
    "\n",
    "            if csvFile2.iloc[n2,  0] > max(csvFile2[\"Biomass\"])-0.01 and csvFile2.iloc[n2,  0] < max(csvFile2[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        n2=0\n",
    "        while n2 < len(csvFile3):\n",
    "\n",
    "            if csvFile3.iloc[n2,  0] > max(csvFile3[\"Biomass\"])-0.01 and csvFile3.iloc[n2,  0] < max(csvFile3[\"Biomass\"])+0.01:\n",
    "                count2= count2+1\n",
    "    \n",
    "            n2= n2+1\n",
    "    \n",
    "        if count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2) and len(csvFile3)<4:\n",
    "            indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "    \n",
    "        elif count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2) and (count2> 1 and count2< len(csvFile3)-1):        \n",
    "            indecr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "        \n",
    "        elif count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2) and (count2> 2 and len(csvFile3) < 6):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2) and (count2> 1 and len(csvFile3) < 3):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count == 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2)) and count2< 2:\n",
    "            indecr_and_stable_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and len(csvFile3)<4:\n",
    "            flat_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and count2< 2:\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "   \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2> 2 and len(csvFile3) < 6):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2> 1 and len(csvFile3) < 3):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        elif count< 0.03*len(csvFile2) and len(csvFile3)<4:\n",
    "            diff_indecr_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 0.03*len(csvFile2) and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            diff_indecr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 0.03*len(csvFile2) and count2< 2:\n",
    "            diff_indecr_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "\n",
    "        elif count< 0.03*len(csvFile2) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 0.03*len(csvFile2) and (count2> 2 and len(csvFile3) < 6):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 0.03*len(csvFile2) and (count2> 1 and len(csvFile3) < 3):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "        i= i+1\n",
    "\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "suffering-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NADH16pp', 'NADH17pp', 'NADH18pp']"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "one_to_three_data_point_below_zero_and_diff_indecr_above_zero= list()\n",
    "one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "one_to_three_data_point_below_zero_and_flat_above_zero= list()\n",
    "\n",
    "if len(under_below_zero_and_over_above_zero)> 0:\n",
    "\n",
    "    for r_id in under_below_zero_and_over_above_zero:    #separates under_below_zero_and_over_above_zero reactions in more specific subcategories\n",
    "        l= list()\n",
    "        n=0\n",
    "        n2=0\n",
    "        count=0\n",
    "        count2=0\n",
    "        r_id = under_below_zero_and_over_above_zero[i]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "        while n < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        n= int((len(csvFile)-1)/2)\n",
    "        l4= list()\n",
    "    \n",
    "        while n < len(csvFile):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l4.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile3= pd.DataFrame (l4, columns = ['Biomass'])\n",
    "        csvFile3.Biomass = csvFile3.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        my_series2 = csvFile3['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "        while n2 < len(csvFile2):\n",
    "\n",
    "            if csvFile2.iloc[n2,  0] > max(csvFile2[\"Biomass\"])-0.01 and csvFile2.iloc[n2,  0] < max(csvFile2[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        n2=0\n",
    "        while n2 < len(csvFile3):\n",
    "\n",
    "            if csvFile3.iloc[n2,  0] > max(csvFile3[\"Biomass\"])-0.01 and csvFile3.iloc[n2,  0] < max(csvFile3[\"Biomass\"])+0.01:\n",
    "                count2= count2+1\n",
    "    \n",
    "            n2= n2+1\n",
    "    \n",
    "        if len(csvFile2)<4 and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):        \n",
    "            indecr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 2 and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            diff_indecr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "        elif len(csvFile2)<4 and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            one_to_three_data_point_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count<2 and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "   \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "            \n",
    "    \n",
    "        elif len(csvFile2)<4 and count2< 0.03*len(csvFile3):\n",
    "            one_to_three_data_point_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and count2< 0.03*len(csvFile3):\n",
    "            indecr_and_stable_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 2 and count2< 0.03*len(csvFile3):\n",
    "            diff_indecr_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "\n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and count2< 0.03*len(csvFile3):\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and count2< 0.03*len(csvFile3):\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and count2< 0.03*len(csvFile3):\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "        \n",
    "    \n",
    "        i= i+1\n",
    "\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "controlling-ceiling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NADH16pp',\n",
       " 'NADH17pp',\n",
       " 'NADH18pp',\n",
       " 'ALAabcpp',\n",
       " 'ASPabcpp',\n",
       " 'CRNDabcpp',\n",
       " 'CRNabcpp',\n",
       " 'CTBTabcpp',\n",
       " 'ARBabcpp',\n",
       " 'ASNabcpp',\n",
       " 'GLUabcpp',\n",
       " 'ILEabcpp',\n",
       " 'HISabcpp',\n",
       " 'LEUabcpp',\n",
       " 'PROabcpp',\n",
       " 'PIuabcpp',\n",
       " 'SUCMALtpp',\n",
       " 'VALabcpp',\n",
       " 'DARBabcpp']"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "if len(over_below_zero_and_over_above_zero)> 0:\n",
    "\n",
    "    for r_id in over_below_zero_and_over_above_zero:    #separates over_below_zero_and_over_above_zero reactions in more specific subcategories\n",
    "        l= list()\n",
    "        n=0\n",
    "        n2=0\n",
    "        count=0\n",
    "        count2=0\n",
    "        r_id = over_below_zero_and_over_above_zero[i]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "        while n < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        n= int((len(csvFile)-1)/2)\n",
    "        l4= list()\n",
    "    \n",
    "        while n < len(csvFile):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l4.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile3= pd.DataFrame (l4, columns = ['Biomass'])\n",
    "        csvFile3.Biomass = csvFile3.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        my_series2 = csvFile3['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "        while n2 < len(csvFile2):\n",
    "\n",
    "            if csvFile2.iloc[n2,  0] > max(csvFile2[\"Biomass\"])-0.01 and csvFile2.iloc[n2,  0] < max(csvFile2[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        n2=0\n",
    "        while n2 < len(csvFile3):\n",
    "\n",
    "            if csvFile3.iloc[n2,  0] > max(csvFile3[\"Biomass\"])-0.01 and csvFile3.iloc[n2,  0] < max(csvFile3[\"Biomass\"])+0.01:\n",
    "                count2= count2+1\n",
    "    \n",
    "            n2= n2+1\n",
    "    \n",
    "        if (count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2)) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):        \n",
    "            indecr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2== 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 0.03*len(csvFile2) and (count2 == 0.03*len(csvFile3) or count2> 0.03*len(csvFile3) and count2< 0.97*len(csvFile3)):\n",
    "            diff_indecr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "        elif (count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count<0.97*len(csvFile2)) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 0.03*len(csvFile2) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "   \n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and (count2 == 0.97*len(csvFile3) or count2> 0.97*len(csvFile3)):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "    \n",
    "        elif (count== 0.03*len(csvFile2) or count> 0.03*len(csvFile2) and count< 0.97*len(csvFile2)) and count2< 0.03*len(csvFile3):\n",
    "            indecr_and_stable_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 0.03*len(csvFile2) and count2< 0.03*len(csvFile3):\n",
    "            diff_indecr_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "\n",
    "        elif (count == 0.97*len(csvFile2) or count> 0.97*len(csvFile2)) and count2< 0.03*len(csvFile3):\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "        i= i+1\n",
    "\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "developed-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NADH16pp',\n",
       " 'NADH17pp',\n",
       " 'NADH18pp',\n",
       " 'ALAabcpp',\n",
       " 'ASPabcpp',\n",
       " 'CRNDabcpp',\n",
       " 'CRNabcpp',\n",
       " 'CTBTabcpp',\n",
       " 'ARBabcpp',\n",
       " 'ASNabcpp',\n",
       " 'GLUabcpp',\n",
       " 'ILEabcpp',\n",
       " 'HISabcpp',\n",
       " 'LEUabcpp',\n",
       " 'PROabcpp',\n",
       " 'PIuabcpp',\n",
       " 'SUCMALtpp',\n",
       " 'VALabcpp',\n",
       " 'DARBabcpp']"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "\n",
    "if len(under_below_zero_and_under_above_zero)> 0:\n",
    "    \n",
    "    for r_id in under_below_zero_and_under_above_zero:    #separates under_below_zero_and_under_above_zero reactions in more specific subcategories\n",
    "        l= list()\n",
    "        n=0\n",
    "        n2=0\n",
    "        count=0\n",
    "        count2=0\n",
    "        r_id = under_below_zero_and_under_above_zero[i]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "\n",
    "        while n < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        n= int((len(csvFile)-1)/2)\n",
    "        l4= list()\n",
    "    \n",
    "        while n < len(csvFile):\n",
    "            inf= csvFile.iloc[n,  2]\n",
    "            flt= float(csvFile.iloc[n,  2])\n",
    "    \n",
    "            if csvFile.iloc[n,  2] == flt:\n",
    "                l4.append(csvFile.iloc[n,  2])\n",
    "            n= n+1\n",
    "\n",
    "        csvFile3= pd.DataFrame (l4, columns = ['Biomass'])\n",
    "        csvFile3.Biomass = csvFile3.Biomass.round(2)\n",
    "    \n",
    "    \n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        my_series2 = csvFile3['Biomass'].squeeze()\n",
    "\n",
    "\n",
    "        while n2 < len(csvFile2):\n",
    "\n",
    "            if csvFile2.iloc[n2,  0] > max(csvFile2[\"Biomass\"])-0.01 and csvFile2.iloc[n2,  0] < max(csvFile2[\"Biomass\"])+0.01:\n",
    "                count= count+1\n",
    "    \n",
    "            n2= n2+1\n",
    "        \n",
    "        n2=0\n",
    "        while n2 < len(csvFile3):\n",
    "\n",
    "            if csvFile3.iloc[n2,  0] > max(csvFile3[\"Biomass\"])-0.01 and csvFile3.iloc[n2,  0] < max(csvFile3[\"Biomass\"])+0.01:\n",
    "                count2= count2+1\n",
    "    \n",
    "            n2= n2+1\n",
    "    \n",
    "        if len(csvFile2)<4 and len(csvFile3)<4:\n",
    "            one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "\n",
    "        elif len(csvFile2)<4 and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "            \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and len(csvFile3)<4:       \n",
    "            indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and len(csvFile3)<4:       \n",
    "            flat_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> 2 and len(csvFile2) < 6) and len(csvFile3)<4:       \n",
    "            flat_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> 1 and len(csvFile2) < 3) and len(csvFile3)<4:       \n",
    "            flat_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "        \n",
    "            \n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2> 1 and count2< len(csvFile3)-1):        \n",
    "            indecr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            flat_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 2 and (count2> 1 and count2< len(csvFile3)-1):\n",
    "            diff_indecr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "        elif len(csvFile2)<4 and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            one_to_three_data_point_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif len(csvFile2)<4 and (count2> 2 and len(csvFile3) < 6):\n",
    "            one_to_three_data_point_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif len(csvFile2)<4 and (count2> 1 and len(csvFile3) < 3):\n",
    "            one_to_three_data_point_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2> 2 and len(csvFile3) < 6):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and (count2> 1 and len(csvFile3) < 3):\n",
    "            indecr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 2 and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 2 and (count2> 2 and len(csvFile3) < 6):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif count< 2 and (count2> 1 and len(csvFile3) < 3):\n",
    "            diff_indecr_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2> 2 and len(csvFile3) < 6):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "        \n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and (count2> 1 and len(csvFile3) < 3):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2> 2 and len(csvFile3) < 6):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and (count2> 1 and len(csvFile3) < 3):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2> len(csvFile3)-3 and len(csvFile3)>5):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2> 2 and len(csvFile3) < 6):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and (count2> 1 and len(csvFile3) < 3):\n",
    "            flat_below_zero_and_flat_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "        elif len(csvFile2)<4 and count2< 2:\n",
    "            one_to_three_data_point_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 2 and len(csvFile3)<4:\n",
    "            diff_indecr_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and count< len(csvFile2)-1) and count2< 2:\n",
    "            indecr_and_stable_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "        \n",
    "        elif count< 2 and count2< 2:\n",
    "            diff_indecr_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "\n",
    "        elif (count> len(csvFile2)-3 and len(csvFile2)>5) and count2< 2:\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 2 and len(csvFile2) < 6) and count2< 2:\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "        elif (count> 1 and len(csvFile2) < 3) and count2< 2:\n",
    "            flat_below_zero_and_diff_indecr_above_zero.append(r_id)\n",
    "    \n",
    "    \n",
    "        i= i+1\n",
    "\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "extraordinary-customer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_indole_e',\n",
       " 'EX_pi_e',\n",
       " '12PPDRtex',\n",
       " '12PPDRtpp',\n",
       " '12PPDStex',\n",
       " '12PPDStpp',\n",
       " 'EX_quin_e',\n",
       " 'EX_skm_e',\n",
       " 'EX_so4_e',\n",
       " 'EX_taur_e',\n",
       " '3HPPtex',\n",
       " 'ABUTtex',\n",
       " 'ACACCT',\n",
       " 'ACALDtex',\n",
       " 'ACALDtpp',\n",
       " '5DGLCNR',\n",
       " '5DGLCNt2rpp',\n",
       " '5DGLCNtex',\n",
       " 'AIRC3',\n",
       " 'AKGt2rpp',\n",
       " 'AKGtex',\n",
       " 'ACSERtex',\n",
       " 'ACtex',\n",
       " 'ADEt2rpp',\n",
       " 'ADEtex',\n",
       " 'ALAtex',\n",
       " 'ALCD19',\n",
       " 'ALCD2x',\n",
       " 'ALDD3y',\n",
       " 'ALLTNt2rpp',\n",
       " 'ALLTNtex',\n",
       " 'ASPtex',\n",
       " 'BALAt2pp',\n",
       " 'BUTCT',\n",
       " 'CITtex',\n",
       " 'CSNt2pp',\n",
       " 'DALAtex',\n",
       " 'DDGLK',\n",
       " 'CYStex',\n",
       " 'DHAtex',\n",
       " 'DHAtpp',\n",
       " 'D_LACt2pp',\n",
       " 'D_LACtex',\n",
       " 'DHORTS',\n",
       " 'DSERt2pp',\n",
       " 'ECOAH4',\n",
       " 'ETHAtex',\n",
       " 'ETOHtex',\n",
       " 'ETOHtrpp',\n",
       " 'ASNtex',\n",
       " 'GLCNtex',\n",
       " 'GLYCAtex',\n",
       " 'GLUR',\n",
       " 'GLUtex',\n",
       " 'GLYALDtex',\n",
       " 'GLYALDtpp',\n",
       " 'GUAtex',\n",
       " 'GLYC3Ptex',\n",
       " 'GLYCAt2rpp',\n",
       " 'H2Stex',\n",
       " 'GLYCLTtex',\n",
       " 'HYXNtex',\n",
       " 'HYXNtpp',\n",
       " 'IDONt2rpp',\n",
       " 'IDONtex',\n",
       " 'IMPC',\n",
       " 'GLYCtex',\n",
       " 'HOMtex',\n",
       " 'L_LACt2rpp',\n",
       " 'GLYtex',\n",
       " 'MALtex',\n",
       " 'OROTt2_2pp',\n",
       " 'ORPT',\n",
       " 'PROtex',\n",
       " 'PYRt2rpp',\n",
       " 'PYRtex',\n",
       " 'PSP_Lpp',\n",
       " 'RBK_L1',\n",
       " 'PTHRpp',\n",
       " 'RIBabcpp',\n",
       " 'SUCCtex',\n",
       " 'SERtex',\n",
       " 'THRtex',\n",
       " 'THYMtex',\n",
       " 'URAtex',\n",
       " 'VALtex',\n",
       " 'XANtex',\n",
       " 'PPAt4pp']"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_below_zero_and_flat_above_zero\n",
    "indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n",
    "indecr_and_stable_below_zero_and_diff_indecr_above_zero\n",
    "one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero\n",
    "one_to_three_data_point_below_zero_and_flat_above_zero\n",
    "one_to_three_data_point_below_zero_and_diff_indecr_above_zero\n",
    "one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero\n",
    "diff_indecr_below_zero_and_diff_indecr_above_zero\n",
    "diff_indecr_below_zero_and_indecr_and_stable_above_zero\n",
    "diff_indecr_below_zero_and_one_to_three_data_point_above_zero\n",
    "flat_below_zero_and_diff_indecr_above_zero\n",
    "flat_below_zero_and_indecr_and_stable_above_zero\n",
    "flat_below_zero_and_one_to_three_data_point_above_zero\n",
    "diff_indecr_below_zero_and_flat_above_zero\n",
    "\n",
    "\n",
    "indecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n",
    "indecr_and_stable_below_zero_and_flat_above_zero\n",
    "one_to_three_data_point_above_zero\n",
    "one_to_three_data_point_below_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "virtual-agreement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indecr_and_stable_below_zero_and_indecr_and_stable_above_zero)+len(indecr_and_stable_below_zero_and_flat_above_zero)+len(one)+len(zero)+len(flat_below_zero_and_flat_above_zero)+len(indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+len(indecr_and_stable_below_zero_and_diff_indecr_above_zero)+len(one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero)+len(one_to_three_data_point_below_zero_and_flat_above_zero)+len(one_to_three_data_point_below_zero_and_diff_indecr_above_zero)+len(one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero)+len(diff_indecr_below_zero_and_diff_indecr_above_zero)+len(diff_indecr_below_zero_and_indecr_and_stable_above_zero)+len(diff_indecr_below_zero_and_one_to_three_data_point_above_zero)+len(flat_below_zero_and_diff_indecr_above_zero)+len(flat_below_zero_and_indecr_and_stable_above_zero)+len(flat_below_zero_and_one_to_three_data_point_above_zero)+len(diff_indecr_below_zero_and_flat_above_zero)+len(one_at_zero)+len(mon_decr_and_stable_above_zero)+len(mon_incr_and_stable_above_zero)+len(inANDdecr_and_stable_above_zero)+len(mon_decr_and_stable_below_zero)+len(mon_incr_and_stable_below_zero)+len(inANDdecr_and_stable_below_zero)+len(flat_above_zero)+len(flat_below_zero)+len(diff_indecr_above_zero)+len(diff_indecr_below_zero)+len(one_to_three_data_point_above_zero)+len(one_to_three_data_point_below_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "demographic-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt= list(indecr_and_stable_below_zero_and_indecr_and_stable_above_zero)+list(indecr_and_stable_below_zero_and_flat_above_zero)+list(one)+list(zero)+list(flat_below_zero_and_flat_above_zero)+list(indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+list(indecr_and_stable_below_zero_and_diff_indecr_above_zero)+list(one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero)+list(one_to_three_data_point_below_zero_and_flat_above_zero)+list(one_to_three_data_point_below_zero_and_diff_indecr_above_zero)+list(one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero)+list(diff_indecr_below_zero_and_diff_indecr_above_zero)+list(diff_indecr_below_zero_and_indecr_and_stable_above_zero)+list(diff_indecr_below_zero_and_one_to_three_data_point_above_zero)+list(flat_below_zero_and_diff_indecr_above_zero)+list(flat_below_zero_and_indecr_and_stable_above_zero)+list(flat_below_zero_and_one_to_three_data_point_above_zero)+list(diff_indecr_below_zero_and_flat_above_zero)+list(one_at_zero)+list(mon_decr_and_stable_above_zero)+list(mon_incr_and_stable_above_zero)+list(inANDdecr_and_stable_above_zero)+list(mon_decr_and_stable_below_zero)+list(mon_incr_and_stable_below_zero)+list(inANDdecr_and_stable_below_zero)+list(flat_above_zero)+list(flat_below_zero)+list(diff_indecr_above_zero)+list(diff_indecr_below_zero)+list(one_to_three_data_point_above_zero)+list(one_to_three_data_point_below_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "split-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[]\n",
    "for i in lt:\n",
    "    if i not in l1:\n",
    "        l1.append(i)\n",
    "    else:\n",
    "        print(i,end=' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "sudden-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFile = pd.read_csv('all reactions.csv')\n",
    "csvFile[\"Reaction names\"]\n",
    "\n",
    "rl= list(csvFile[\"Reaction names\"])\n",
    "\n",
    "set1= set(rl)\n",
    "set2= set(lt)\n",
    "set3= set1-set2\n",
    "set3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "reserved-canberra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_ac_e', 'H2SO', 'SULabcpp']"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "incr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "decr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero:                    #this code finds which of the indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero reactions have an increasing and stable trend and which a decreasing and stable trend below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "        type(my_series)\n",
    "\n",
    "        if my_series.is_monotonic_decreasing ==True:\n",
    "            decr_and_stable_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "        elif my_series.is_monotonic ==True:\n",
    "            incr_and_stable_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "decr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set2= set(decr_and_stable_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set3= set(incr_and_stable_below_zero_and_one_to_three_data_point_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "unlimited-kennedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SULabcpp']"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero):       #this code finds inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero reactions that are not truly both increasing and decreasing and stable below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "    \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "sunrise-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero= list(unclassified_below_zero_and_one_to_three_data_point_above_zero)\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "technical-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list(set5)\n",
    "\n",
    "decr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list(decr_and_stable_below_zero_and_one_to_three_data_point_above_zero) + list(w3)\n",
    "incr_and_stable_below_zero_and_one_to_three_data_point_above_zero= list(incr_and_stable_below_zero_and_one_to_three_data_point_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "unlikely-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "indecr_and_stable_below_zero_and_mon_incr_above_zero= list()\n",
    "indecr_and_stable_below_zero_and_mon_decr_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_diff_indecr_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_diff_indecr_above_zero:                  #this code finds which of the indecr_and_stable_below_zero_and_diff_indecr_above_zero reactions have an increasing trend and which a decreasing trend above zero\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_diff_indecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                indecr_and_stable_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                indecr_and_stable_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_diff_indecr_above_zero)\n",
    "set2= set(indecr_and_stable_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(indecr_and_stable_below_zero_and_mon_incr_above_zero)\n",
    "indecr_and_stable_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "indecr_and_stable_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "republican-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(indecr_and_stable_below_zero_and_inANDdecr_above_zero):       #this code finds indecr_and_stable_below_zero_and_inANDdecr_above_zero reactions that are not truly both increasing and decreasing and stable above zero\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = indecr_and_stable_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        \n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "yellow-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "indecr_and_stable_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(indecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(indecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "indecr_and_stable_below_zero_and_unclassified_above_zero= list(indecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "indecr_and_stable_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "applicable-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= set(indecr_and_stable_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(indecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "indecr_and_stable_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "indecr_and_stable_below_zero_and_mon_decr_above_zero= list(indecr_and_stable_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "indecr_and_stable_below_zero_and_mon_incr_above_zero= list(indecr_and_stable_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "endless-origin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NI2uabcpp',\n",
       " 'H2Otpp',\n",
       " 'Kabcpp',\n",
       " 'THD2pp',\n",
       " 'EX_for_e',\n",
       " 'PPA',\n",
       " 'MNt2pp',\n",
       " 'ARGDCpp',\n",
       " 'H2Otex',\n",
       " 'ZNabcpp',\n",
       " 'CBPS']"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "decr_and_stable_below_zero_and_mon_decr_above_zero= list()\n",
    "incr_and_stable_below_zero_and_mon_decr_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_mon_decr_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_mon_decr_above_zero:                #this code finds which of the indecr_and_stable_below_zero_and_mon_decr_above_zero reactions have an increasing and stable trend and which a decreasing and stable trend below zero\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_mon_decr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                decr_and_stable_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                incr_and_stable_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_mon_decr_above_zero)\n",
    "set2= set(decr_and_stable_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(incr_and_stable_below_zero_and_mon_decr_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "irish-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NI2uabcpp', 'Kabcpp', 'PPA', 'MNt2pp', 'ARGDCpp', 'ZNabcpp', 'CBPS']"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_mon_decr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_mon_decr_above_zero):       #this code finds inANDdecr_and_stable_below_zero_and_mon_decr_above_zero reactions that are not truly both increasing and decreasing and stable below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_mon_decr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "intensive-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_mon_decr_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_mon_decr_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_mon_decr_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_mon_decr_above_zero= list(unclassified_below_zero_and_mon_decr_above_zero)\n",
    "unclassified_below_zero_and_mon_decr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "experimental-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_mon_decr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_mon_decr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_above_zero= list(set5)\n",
    "\n",
    "decr_and_stable_below_zero_and_mon_decr_above_zero= list(decr_and_stable_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "incr_and_stable_below_zero_and_mon_decr_above_zero= list(incr_and_stable_below_zero_and_mon_decr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "drawn-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "decr_and_stable_below_zero_and_mon_incr_above_zero= list()\n",
    "incr_and_stable_below_zero_and_mon_incr_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_mon_incr_above_zero)> 0:\n",
    "\n",
    "    for r_id in indecr_and_stable_below_zero_and_mon_incr_above_zero:              #this code finds which of the indecr_and_stable_below_zero_and_mon_incr_above_zero reactions have an increasing and stable trend and which a decreasing and stable trend below zero\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_mon_incr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                decr_and_stable_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                incr_and_stable_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_mon_incr_above_zero)\n",
    "set2= set(decr_and_stable_below_zero_and_mon_incr_above_zero)\n",
    "set3= set(incr_and_stable_below_zero_and_mon_incr_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "homeless-account",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_mon_incr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_mon_incr_above_zero):       #this code finds inANDdecr_and_stable_below_zero_and_mon_incr_above_zero reactions that are not truly both increasing and decreasing and stable below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_mon_incr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "future-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_mon_incr_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_mon_incr_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_mon_incr_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_mon_incr_above_zero= list(unclassified_below_zero_and_mon_incr_above_zero)\n",
    "unclassified_below_zero_and_mon_incr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "behavioral-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_mon_incr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_mon_incr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_above_zero= list(set5)\n",
    "\n",
    "decr_and_stable_below_zero_and_mon_incr_above_zero= list(decr_and_stable_below_zero_and_mon_incr_above_zero) + list(w3)\n",
    "incr_and_stable_below_zero_and_mon_incr_above_zero= list(incr_and_stable_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "adapted-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "decr_and_stable_below_zero_and_inANDdecr_above_zero= list()\n",
    "incr_and_stable_below_zero_and_inANDdecr_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_inANDdecr_above_zero)> 0:\n",
    "\n",
    "    for r_id in indecr_and_stable_below_zero_and_inANDdecr_above_zero:           #this code finds which of the indecr_and_stable_below_zero_and_inANDdecr_above_zero reactions have an increasing and stable trend and which a decreasing and stable trend below zero\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                decr_and_stable_below_zero_and_inANDdecr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                incr_and_stable_below_zero_and_inANDdecr_above_zero.append(r_id)\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(decr_and_stable_below_zero_and_inANDdecr_above_zero)\n",
    "set3= set(incr_and_stable_below_zero_and_inANDdecr_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "empirical-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero):       #this code finds inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero reactions that are not truly both increasing and decreasing and stable below zero\n",
    "    \n",
    "        i=0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < ((len(csvFile)-1)/2)+1:\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "weekly-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_inANDdecr_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_inANDdecr_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_inANDdecr_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_inANDdecr_above_zero= list(unclassified_below_zero_and_inANDdecr_above_zero)\n",
    "unclassified_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "environmental-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_inANDdecr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "decr_and_stable_below_zero_and_mon_incr_above_zero= list(decr_and_stable_below_zero_and_mon_incr_above_zero) + list(w3)\n",
    "incr_and_stable_below_zero_and_mon_incr_above_zero= list(incr_and_stable_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "worldwide-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUCDi']"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "one_to_three_data_point_below_zero_and_incr_and_stable_above_zero= list()\n",
    "one_to_three_data_point_below_zero_and_decr_and_stable_above_zero= list()\n",
    "\n",
    "if len(one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                one_to_three_data_point_below_zero_and_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                one_to_three_data_point_below_zero_and_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(one_to_three_data_point_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(one_to_three_data_point_below_zero_and_decr_and_stable_above_zero)\n",
    "set3= set(one_to_three_data_point_below_zero_and_incr_and_stable_above_zero)\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "mighty-interest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUCDi']"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "structured-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero= list(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "mysterious-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "one_to_three_data_point_below_zero_and_decr_and_stable_above_zero= list(one_to_three_data_point_below_zero_and_decr_and_stable_above_zero) + list(w3)\n",
    "one_to_three_data_point_below_zero_and_incr_and_stable_above_zero= list(one_to_three_data_point_below_zero_and_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "prime-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FUM']"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "one_to_three_data_point_below_zero_and_mon_incr_above_zero= list()\n",
    "one_to_three_data_point_below_zero_and_mon_decr_above_zero= list()\n",
    "\n",
    "if len(one_to_three_data_point_below_zero_and_diff_indecr_above_zero)>0:\n",
    "    \n",
    "    for r_id in one_to_three_data_point_below_zero_and_diff_indecr_above_zero:\n",
    "    \n",
    "        r_id = one_to_three_data_point_below_zero_and_diff_indecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                one_to_three_data_point_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                one_to_three_data_point_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(one_to_three_data_point_below_zero_and_diff_indecr_above_zero)\n",
    "set2= set(one_to_three_data_point_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(one_to_three_data_point_below_zero_and_mon_incr_above_zero)\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "adjustable-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FUM']"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(one_to_three_data_point_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(one_to_three_data_point_below_zero_and_inANDdecr_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = one_to_three_data_point_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "dangerous-luther",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero= list(one_to_three_data_point_below_zero_and_unclassified_above_zero)+list(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "assigned-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(one_to_three_data_point_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "one_to_three_data_point_below_zero_and_mon_decr_above_zero= list(one_to_three_data_point_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "one_to_three_data_point_below_zero_and_mon_incr_above_zero= list(one_to_three_data_point_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "subject-interference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENO', 'MDH', 'EX_co2_e', 'ATPS4rpp', 'CYTBO3_4pp']"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "diff_indecr_below_zero_and_mon_incr_above_zero= list()\n",
    "diff_indecr_below_zero_and_mon_decr_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_diff_indecr_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_diff_indecr_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_diff_indecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                diff_indecr_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                diff_indecr_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_diff_indecr_above_zero)\n",
    "set2= set(diff_indecr_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(diff_indecr_below_zero_and_mon_incr_above_zero)\n",
    "diff_indecr_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "diff_indecr_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "virgin-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENO', 'MDH']"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(diff_indecr_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(diff_indecr_below_zero_and_inANDdecr_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = diff_indecr_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "annoying-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero= list(one_to_three_data_point_below_zero_and_unclassified_above_zero)+list(one_to_three_data_point_below_zero_and_unclassified_above_zero2)\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "divine-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(one_to_three_data_point_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "diff_indecr_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "diff_indecr_below_zero_and_mon_decr_above_zero= list(diff_indecr_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "diff_indecr_below_zero_and_mon_incr_above_zero= list(diff_indecr_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "split-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PPCK',\n",
       " 'GLYCDx',\n",
       " 'GLUDy',\n",
       " 'PPS',\n",
       " 'CO2tex',\n",
       " 'FE3abcpp',\n",
       " 'PGM',\n",
       " 'CO2tpp',\n",
       " 'FLDR2',\n",
       " 'FBP',\n",
       " 'CAT']"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_mon_decr_above_zero= list()\n",
    "mon_incr_below_zero_and_mon_decr_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_mon_decr_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_mon_decr_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_mon_decr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_mon_decr_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_mon_decr_above_zero)\n",
    "inANDdecr_below_zero_and_mon_decr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_mon_decr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "solid-edmonton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_mon_decr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_mon_decr_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_mon_decr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "        \n",
    "        \n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "distinguished-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PPCK', 'GLYCDx', 'GLUDy', 'PPS', 'PGM', 'FLDR2', 'FBP']"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "unnecessary-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_mon_decr_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_mon_decr_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_mon_decr_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_mon_decr_above_zero= list(unclassified_below_zero_and_mon_decr_above_zero)+list(unclassified_below_zero_and_mon_decr_above_zero2)\n",
    "unclassified_below_zero_and_mon_decr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "small-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_mon_decr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_mon_decr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_mon_decr_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_mon_decr_above_zero= list(mon_decr_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_mon_decr_above_zero= list(mon_incr_below_zero_and_mon_decr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "coupled-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_mon_incr_above_zero= list()\n",
    "mon_incr_below_zero_and_mon_incr_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_mon_incr_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_mon_incr_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_mon_incr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_mon_incr_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_mon_incr_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_mon_incr_above_zero)\n",
    "inANDdecr_below_zero_and_mon_incr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_mon_incr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "alleged-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_mon_incr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_mon_incr_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_mon_incr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "republican-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_mon_incr_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_mon_incr_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_mon_incr_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_mon_incr_above_zero= list(unclassified_below_zero_and_mon_incr_above_zero)+list(unclassified_below_zero_and_mon_incr_above_zero2)\n",
    "unclassified_below_zero_and_mon_incr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "chinese-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_mon_incr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_mon_incr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_mon_incr_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_mon_incr_above_zero= list(mon_decr_below_zero_and_mon_incr_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_mon_incr_above_zero= list(mon_incr_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "enormous-donna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_inANDdecr_above_zero= list()\n",
    "mon_incr_below_zero_and_inANDdecr_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_inANDdecr_above_zero:                  \n",
    "        \n",
    "        r_id = diff_indecr_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_inANDdecr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_inANDdecr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_inANDdecr_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_inANDdecr_above_zero)\n",
    "inANDdecr_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "adverse-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_inANDdecr_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "swiss-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_inANDdecr_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_inANDdecr_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_inANDdecr_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_inANDdecr_above_zero= list(unclassified_below_zero_and_inANDdecr_above_zero)+list(unclassified_below_zero_and_inANDdecr_above_zero2)\n",
    "unclassified_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "floating-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_inANDdecr_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_inANDdecr_above_zero= list(mon_decr_below_zero_and_inANDdecr_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_inANDdecr_above_zero= list(mon_incr_below_zero_and_inANDdecr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "focal-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "mon_incr_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_indecr_and_stable_above_zero)\n",
    "inANDdecr_below_zero_and_indecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "czech-sigma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_indecr_and_stable_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int(((len(csvFile)-1)/2)+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "durable-division",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero= list(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "clinical-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_indecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_indecr_and_stable_above_zero= list(mon_decr_below_zero_and_indecr_and_stable_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_indecr_and_stable_above_zero= list(mon_incr_below_zero_and_indecr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "private-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "inANDdecr_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "inANDdecr_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(inANDdecr_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in inANDdecr_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = inANDdecr_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                inANDdecr_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                inANDdecr_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(inANDdecr_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(inANDdecr_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "nonprofit-register",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "involved-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "inANDdecr_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(inANDdecr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(inANDdecr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "inANDdecr_below_zero_and_unclassified_above_zero= list(inANDdecr_below_zero_and_unclassified_above_zero)\n",
    "inANDdecr_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "aboriginal-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(inANDdecr_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "inANDdecr_below_zero_and_mon_decr_and_stable_above_zero= list(inANDdecr_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "inANDdecr_below_zero_and_mon_incr_and_stable_above_zero= list(inANDdecr_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "interesting-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "mon_decr_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(mon_decr_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in mon_decr_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = mon_decr_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_decr_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(mon_decr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(mon_decr_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "mon_decr_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "mon_decr_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "affiliated-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(mon_decr_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(mon_decr_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = mon_decr_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "manual-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "mon_decr_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(mon_decr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(mon_decr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "mon_decr_below_zero_and_unclassified_above_zero= list(mon_decr_below_zero_and_unclassified_above_zero)\n",
    "mon_decr_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "fixed-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(mon_decr_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(mon_decr_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "mon_decr_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_mon_decr_and_stable_above_zero= list(mon_decr_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "mon_decr_below_zero_and_mon_incr_and_stable_above_zero= list(mon_decr_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "sunset-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_h2o_e']"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "mon_incr_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(mon_incr_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in mon_incr_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = mon_incr_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_incr_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(mon_incr_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_incr_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "mon_incr_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "mon_incr_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "english-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(mon_incr_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(mon_incr_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = mon_incr_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "greenhouse-bookmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "mon_incr_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(mon_incr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(mon_incr_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "mon_incr_below_zero_and_unclassified_above_zero= list(mon_incr_below_zero_and_unclassified_above_zero)\n",
    "mon_incr_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "caring-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(mon_incr_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(mon_incr_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "mon_incr_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_incr_below_zero_and_mon_decr_and_stable_above_zero= list(mon_incr_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_mon_incr_and_stable_above_zero= list(mon_incr_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "inner-device",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_etoh_e',\n",
       " 'EX_pro__L_e',\n",
       " 'EX_glyc_e',\n",
       " 'EX_12ppd__S_e',\n",
       " 'EX_ala__D_e',\n",
       " 'EX_asn__L_e',\n",
       " 'EX_succ_e',\n",
       " 'EX_idon__L_e',\n",
       " 'EX_alltn_e',\n",
       " 'EX_4abut_e',\n",
       " 'EX_gua_e',\n",
       " 'EX_ade_e',\n",
       " 'EX_glyc__R_e',\n",
       " 'EX_xan_e']"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "mon_incr_below_zero_and_one_to_three_data_point_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_one_to_three_data_point_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_one_to_three_data_point_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_one_to_three_data_point_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_one_to_three_data_point_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_one_to_three_data_point_above_zero)\n",
    "inANDdecr_below_zero_and_one_to_three_data_point_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_one_to_three_data_point_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "dutch-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_ala__D_e']"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_one_to_three_data_point_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_one_to_three_data_point_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_one_to_three_data_point_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "neither-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_one_to_three_data_point_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_one_to_three_data_point_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero= list(unclassified_below_zero_and_one_to_three_data_point_above_zero)+list(unclassified_below_zero_and_one_to_three_data_point_above_zero2)\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "cognitive-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_one_to_three_data_point_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_one_to_three_data_point_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_one_to_three_data_point_above_zero= list(mon_decr_below_zero_and_one_to_three_data_point_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_one_to_three_data_point_above_zero= list(mon_incr_below_zero_and_one_to_three_data_point_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "fatty-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "flat_below_zero_and_mon_decr_above_zero= list()\n",
    "flat_below_zero_and_mon_incr_above_zero= list()\n",
    "\n",
    "if len(flat_below_zero_and_diff_indecr_above_zero)>0:\n",
    "    \n",
    "    for r_id in flat_below_zero_and_diff_indecr_above_zero:\n",
    "    \n",
    "        r_id = flat_below_zero_and_diff_indecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                flat_below_zero_and_mon_decr_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                flat_below_zero_and_mon_incr_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(flat_below_zero_and_diff_indecr_above_zero)\n",
    "set2= set(flat_below_zero_and_mon_decr_above_zero)\n",
    "set3= set(flat_below_zero_and_mon_incr_above_zero)\n",
    "flat_below_zero_and_inANDdecr_above_zero= list(set1-set2-set3)\n",
    "flat_below_zero_and_inANDdecr_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "vertical-winning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(flat_below_zero_and_inANDdecr_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(flat_below_zero_and_inANDdecr_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = flat_below_zero_and_inANDdecr_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "legal-silicon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "flat_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(flat_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(flat_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "flat_below_zero_and_unclassified_above_zero= list(flat_below_zero_and_unclassified_above_zero)\n",
    "flat_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "social-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(flat_below_zero_and_inANDdecr_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(flat_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "flat_below_zero_and_inANDdecr_above_zero= list(set5)\n",
    "\n",
    "flat_below_zero_and_mon_decr_above_zero= list(flat_below_zero_and_mon_decr_above_zero) + list(w3)\n",
    "flat_below_zero_and_mon_incr_above_zero= list(flat_below_zero_and_mon_incr_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "selective-browse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "flat_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "flat_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(flat_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in flat_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = flat_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                flat_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                flat_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(flat_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(flat_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(flat_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "flat_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "flat_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "facial-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(flat_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(flat_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = flat_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "collected-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "flat_below_zero_and_unclassified_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(flat_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(flat_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "flat_below_zero_and_unclassified_above_zero= list(flat_below_zero_and_unclassified_above_zero)+list(flat_below_zero_and_unclassified_above_zero2)\n",
    "flat_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "romance-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(flat_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(flat_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "flat_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "flat_below_zero_and_mon_decr_and_stable_above_zero= list(flat_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "flat_below_zero_and_mon_incr_and_stable_above_zero= list(flat_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "amended-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_flat_above_zero= list()\n",
    "mon_incr_below_zero_and_flat_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_flat_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_flat_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_flat_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_flat_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_flat_above_zero)\n",
    "inANDdecr_below_zero_and_flat_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "colored-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_flat_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "accessory-lying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_flat_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_flat_above_zero= list(unclassified_below_zero_and_flat_above_zero)\n",
    "unclassified_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "instant-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_flat_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_flat_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_flat_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_flat_above_zero= list(mon_decr_below_zero_and_flat_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_flat_above_zero= list(mon_incr_below_zero_and_flat_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "internal-simpson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_and_stable_below_zero_and_flat_above_zero= list()\n",
    "mon_incr_and_stable_below_zero_and_flat_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_flat_above_zero:\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_flat_above_zero)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_flat_above_zero)\n",
    "set3= set(mon_incr_and_stable_below_zero_and_flat_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_flat_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "international-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_flat_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "colored-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_flat_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_flat_above_zero= list(unclassified_below_zero_and_flat_above_zero)+list(unclassified_below_zero_and_flat_above_zero2)\n",
    "unclassified_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "opening-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_flat_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_flat_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_flat_above_zero= list(set5)\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_flat_above_zero= list(mon_decr_and_stable_below_zero_and_flat_above_zero) + list(w3)\n",
    "mon_incr_and_stable_below_zero_and_flat_above_zero= list(mon_incr_and_stable_below_zero_and_flat_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "disturbed-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_below_zero_and_flat_above_zero= list()\n",
    "mon_incr_below_zero_and_flat_above_zero= list()\n",
    "\n",
    "if len(diff_indecr_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    for r_id in diff_indecr_below_zero_and_flat_above_zero:\n",
    "    \n",
    "        r_id = diff_indecr_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_below_zero_and_flat_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_below_zero_and_flat_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(diff_indecr_below_zero_and_flat_above_zero)\n",
    "set2= set(mon_decr_below_zero_and_flat_above_zero)\n",
    "set3= set(mon_incr_below_zero_and_flat_above_zero)\n",
    "inANDdecr_below_zero_and_flat_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "adapted-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_below_zero_and_flat_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_below_zero_and_flat_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_below_zero_and_flat_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "forty-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_flat_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_flat_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_flat_above_zero= list(unclassified_below_zero_and_flat_above_zero)+list(unclassified_below_zero_and_flat_above_zero2)\n",
    "unclassified_below_zero_and_flat_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "explicit-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_below_zero_and_flat_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_flat_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_below_zero_and_flat_above_zero= list(set5)\n",
    "\n",
    "mon_decr_below_zero_and_flat_above_zero= list(mon_decr_below_zero_and_flat_above_zero) + list(w3)\n",
    "mon_incr_below_zero_and_flat_above_zero= list(mon_incr_below_zero_and_flat_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "brutal-margin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIuabcpp']"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set3= set(mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "caring-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIuabcpp']"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "ceramic-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_indecr_and_stable_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_indecr_and_stable_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero= list(unclassified_below_zero_and_indecr_and_stable_above_zero)+list(unclassified_below_zero_and_indecr_and_stable_above_zero2)\n",
    "unclassified_below_zero_and_indecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "handled-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero= list(mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero) + list(w3)\n",
    "mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero= list(mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "secondary-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "demanding-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "catholic-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero= list(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "interpreted-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list(inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list(inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "grave-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(mon_decr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "average-messenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "packed-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero= list(mon_decr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "ignored-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(mon_decr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list(mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list(mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "invisible-novel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(mon_incr_and_stable_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "threaded-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "ignored-flush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(mon_incr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(mon_incr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero= list(mon_incr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "thousand-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(mon_incr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero= list(mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero= list(mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "authorized-worry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero= list()\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero= list()\n",
    "\n",
    "if len(indecr_and_stable_below_zero_and_unclassified_above_zero)>0:\n",
    "    \n",
    "    for r_id in indecr_and_stable_below_zero_and_unclassified_above_zero:\n",
    "    \n",
    "        r_id = indecr_and_stable_below_zero_and_unclassified_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= 0\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                mon_decr_and_stable_below_zero_and_unclassified_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                mon_incr_and_stable_below_zero_and_unclassified_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(indecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set2= set(mon_decr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set3= set(mon_incr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero= list(set1-set2-set3)\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "visible-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(inANDdecr_and_stable_below_zero_and_unclassified_above_zero):\n",
    "    \n",
    "        i= 0\n",
    "        r_id = inANDdecr_and_stable_below_zero_and_unclassified_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < int((len(csvFile)-1)/2+1):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "orange-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_unclassified_above_zero = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_unclassified_above_zero)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_unclassified_above_zero= list(unclassified_below_zero_and_unclassified_above_zero)\n",
    "unclassified_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "hazardous-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero= list(set5)\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero= list(mon_decr_and_stable_below_zero_and_unclassified_above_zero) + list(w3)\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero= list(mon_incr_and_stable_below_zero_and_unclassified_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "sitting-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2= 0\n",
    "unclassified_below_zero_and_mon_decr_and_stable_above_zero= list()\n",
    "unclassified_below_zero_and_mon_incr_and_stable_above_zero= list()\n",
    "\n",
    "if len(unclassified_below_zero_and_indecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    for r_id in unclassified_below_zero_and_indecr_and_stable_above_zero:\n",
    "    \n",
    "        r_id = unclassified_below_zero_and_indecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        n2= int((len(csvFile)-1)/2)\n",
    "        l= list()\n",
    "    \n",
    "        while n2 < len(csvFile):\n",
    "            inf= csvFile.iloc[n2,  2]\n",
    "            flt= float(csvFile.iloc[n2,  2])\n",
    "    \n",
    "            if csvFile.iloc[n2,  2] == flt:\n",
    "                l.append(csvFile.iloc[n2,  2])\n",
    "            n2= n2+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "\n",
    "        my_series = csvFile2['Biomass'].squeeze()\n",
    "    \n",
    "        if len(csvFile2['Biomass'])>1:\n",
    "        \n",
    "            if my_series.is_monotonic_decreasing ==True:\n",
    "                unclassified_below_zero_and_mon_decr_and_stable_above_zero.append(r_id)\n",
    "            elif my_series.is_monotonic ==True:\n",
    "                unclassified_below_zero_and_mon_incr_and_stable_above_zero.append(r_id)\n",
    "\n",
    "    \n",
    "        i2= i2 + 1\n",
    "\n",
    "set1= set(unclassified_below_zero_and_indecr_and_stable_above_zero)\n",
    "set2= set(unclassified_below_zero_and_mon_decr_and_stable_above_zero)\n",
    "set3= set(unclassified_below_zero_and_mon_incr_and_stable_above_zero)\n",
    "unclassified_below_zero_and_inANDdecr_and_stable_above_zero= list(set1-set2-set3)\n",
    "unclassified_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "alpha-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3= list()\n",
    "w4= list()\n",
    "i2=0\n",
    "\n",
    "if len(unclassified_below_zero_and_inANDdecr_and_stable_above_zero)>0:\n",
    "    \n",
    "    while i2 < len(unclassified_below_zero_and_inANDdecr_and_stable_above_zero):\n",
    "    \n",
    "        i= int((len(csvFile)-1)/2)\n",
    "        r_id = unclassified_below_zero_and_inANDdecr_and_stable_above_zero[i2]\n",
    "        csvFile = pd.read_csv('biomass_per_flux_for_reaction_{}.csv'.format(r_id))\n",
    "        l= list()\n",
    "\n",
    "        while i < len(csvFile):\n",
    "            inf= csvFile.iloc[i,  2]\n",
    "            flt= float(csvFile.iloc[i,  2])\n",
    "    \n",
    "            if csvFile.iloc[i,  2] == flt:\n",
    "                l.append(csvFile.iloc[i,  2])\n",
    "            i= i+1\n",
    "\n",
    "        csvFile2= pd.DataFrame (l, columns = ['Biomass'])\n",
    "        csvFile2.Biomass = csvFile2.Biomass.round(2)\n",
    "        l= list(csvFile2.Biomass)\n",
    "\n",
    "        n2=0\n",
    "\n",
    "        if l[n2] <max(l) and l[n2+1]<max(l) and (l[n2+2] < max(l) or l[n2+2] == max(l)):\n",
    "            n2=0\n",
    "        elif l[n2] == max(l):\n",
    "            n2=0\n",
    "        else:\n",
    "            w3.append(r_id)\n",
    "\n",
    "    \n",
    "        n2= len(l)-1\n",
    "\n",
    "        if l[n2] <max(l) and l[n2-1]<max(l) and (l[n2-2] < max(l) or l[n2-2] == max(l)):\n",
    "            n2= len(l)-1\n",
    "        elif l[n2] == max(l):\n",
    "            n2= len(l)-1\n",
    "        else:\n",
    "            w4.append(r_id)\n",
    "            \n",
    "            \n",
    "        i2= i2+1\n",
    "\n",
    "w3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "secure-marking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = pd.Series(np.union1d(w3, w4))\n",
    "unclassified_below_zero_and_unclassified_above_zero2 = pd.Series(np.intersect1d(w3, w4))\n",
    "\n",
    "set1= set(w3)\n",
    "set2= set(unclassified_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w3= list(set3)\n",
    "\n",
    "set1= set(w4)\n",
    "set2= set(unclassified_below_zero_and_unclassified_above_zero2)\n",
    "set3= set1-set2\n",
    "w4= list(set3)\n",
    "\n",
    "unclassified_below_zero_and_unclassified_above_zero= list(unclassified_below_zero_and_unclassified_above_zero)+list(unclassified_below_zero_and_unclassified_above_zero2)\n",
    "unclassified_below_zero_and_unclassified_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "fossil-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "w4\n",
    "\n",
    "set1= set(unclassified_below_zero_and_inANDdecr_and_stable_above_zero)\n",
    "set2= set(w3)\n",
    "set3= set(w4)\n",
    "set4= set(unclassified_below_zero_and_unclassified_above_zero)\n",
    "set5= set1-set2-set3-set4\n",
    "unclassified_below_zero_and_inANDdecr_and_stable_above_zero= list(set5)\n",
    "\n",
    "unclassified_below_zero_and_mon_decr_and_stable_above_zero= list(unclassified_below_zero_and_mon_decr_and_stable_above_zero) + list(w3)\n",
    "unclassified_below_zero_and_mon_incr_and_stable_above_zero= list(unclassified_below_zero_and_mon_incr_and_stable_above_zero) + list(w4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "superb-chocolate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRD3', 'MALt3pp', 'SUCCt3pp']"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_decr_and_stable_above_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "hybrid-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= pd.DataFrame (one, columns = ['Reaction names'])\n",
    "d.to_csv(\"FINAL one feasible value NOT at zero reactions cut off 2.csv\")\n",
    "d1= pd.DataFrame (zero, columns = ['Reaction names'])\n",
    "d1.to_csv(\"FINAL zero reactions cut off 2.csv\")\n",
    "D= pd.DataFrame (one_at_zero, columns = ['Reaction names'])\n",
    "D.to_csv(\"FINAL one feasible value at zero reactions cut off 2.csv\")\n",
    "D1= pd.DataFrame (flat_above_zero, columns = ['Reaction names'])\n",
    "D1.to_csv(\"FINAL flat above zero reactions cut off 2.csv\")\n",
    "D2= pd.DataFrame (flat_below_zero, columns = ['Reaction names'])\n",
    "D2.to_csv(\"FINAL flat below zero reactions cut off 2.csv\")\n",
    "D3= pd.DataFrame (mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D3.to_csv(\"FINAL mon_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D4= pd.DataFrame (mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D4.to_csv(\"FINAL mon_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D5= pd.DataFrame (inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D5.to_csv(\"FINAL inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D6= pd.DataFrame (mon_decr_and_stable_below_zero, columns = ['Reaction names'])\n",
    "D6.to_csv(\"FINAL increasing and stable below zero reactions cut off 2.csv\")\n",
    "D7= pd.DataFrame (mon_incr_and_stable_below_zero, columns = ['Reaction names'])\n",
    "D7.to_csv(\"FINAL decreasing and stable below reactions cut off 2.csv\")\n",
    "D8= pd.DataFrame (inANDdecr_and_stable_below_zero, columns = ['Reaction names'])\n",
    "D8.to_csv(\"FINAL inANDdecr_and_stable_below_zero reactions cut off 2.csv\")\n",
    "D9= pd.DataFrame (decr_and_stable_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D9.to_csv(\"FINAL increasing and stable below zero and one to three data point above zero reactions cut off 2.csv\")\n",
    "D10= pd.DataFrame (incr_and_stable_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D10.to_csv(\"FINAL decreasing and stable below zero and one to three data point above zero reactions cut off 2.csv\")\n",
    "D11= pd.DataFrame (inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D11.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D12= pd.DataFrame (decr_and_stable_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D12.to_csv(\"FINAL increasing and stable below zero and decreasing above zero reactions cut off 2.csv\")\n",
    "D13= pd.DataFrame (incr_and_stable_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D13.to_csv(\"FINAL decreasing and stable below zero and decreasing above zero reactions cut off 2.csv\")\n",
    "D14= pd.DataFrame (inANDdecr_and_stable_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D14.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D15= pd.DataFrame (decr_and_stable_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D15.to_csv(\"FINAL increasing and stable below zero and increasing above zero reactions cut off 2.csv\")\n",
    "D16= pd.DataFrame (incr_and_stable_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D16.to_csv(\"FINAL decreasing and stable below zero and increasing above zero reactions cut off 2.csv\")\n",
    "D17= pd.DataFrame (inANDdecr_and_stable_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D17.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D18= pd.DataFrame (decr_and_stable_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D18.to_csv(\"FINAL increasing and stable below zero and increasing and decreasing above zero reactions cut off 2.csv\")\n",
    "D19= pd.DataFrame (incr_and_stable_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D19.to_csv(\"FINAL decreasing and stable below zero and increasing and decreasing above zero reactions cut off 2.csv\")\n",
    "D20= pd.DataFrame (inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D20.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D21= pd.DataFrame (one_to_three_data_point_below_zero_and_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D21.to_csv(\"FINAL one_to_three_data_point_below_zero_and_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D22= pd.DataFrame (one_to_three_data_point_below_zero_and_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D22.to_csv(\"FINAL one_to_three_data_point_below_zero_and_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D23= pd.DataFrame (one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D23.to_csv(\"FINAL one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D24= pd.DataFrame (one_to_three_data_point_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D24.to_csv(\"FINAL one_to_three_data_point_below_zero_and_mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D25= pd.DataFrame (one_to_three_data_point_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D25.to_csv(\"FINAL one_to_three_data_point_below_zero_and_mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D26= pd.DataFrame (one_to_three_data_point_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D26.to_csv(\"FINAL one_to_three_data_point_below_zero_and_inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D27= pd.DataFrame (inANDdecr_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D27.to_csv(\"FINAL inANDdecr_below_zero_and_mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D28= pd.DataFrame (mon_decr_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D28.to_csv(\"FINAL increasing below zero decreasing above zero reactions cut off 2.csv\")\n",
    "D29= pd.DataFrame (mon_incr_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D29.to_csv(\"FINAL decreasing below zero decreasing above zero reactions cut off 2.csv\")\n",
    "D30= pd.DataFrame (inANDdecr_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D30.to_csv(\"FINAL inANDdecr_below_zero_and_mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D31= pd.DataFrame (mon_decr_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D31.to_csv(\"FINAL increasing below zero and increasing above zero reactions cut off 2.csv\")\n",
    "D32= pd.DataFrame (mon_incr_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D32.to_csv(\"FINAL decreasing below zero and increasing above zero reactions cut off 2.csv\")\n",
    "D33= pd.DataFrame (inANDdecr_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D33.to_csv(\"FINAL inANDdecr_below_zero_and_inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D34= pd.DataFrame (mon_decr_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D34.to_csv(\"FINAL increasing below zero and increasing and decreasing above zero reactions cut off 2.csv\")\n",
    "D35= pd.DataFrame (mon_incr_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D35.to_csv(\"FINAL decreasing below zero and increasing and decreasing above zero reactions cut off 2.csv\")\n",
    "D36= pd.DataFrame (inANDdecr_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D36.to_csv(\"FINAL inANDdecr_below_zero_and_mon_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D37= pd.DataFrame (inANDdecr_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D37.to_csv(\"FINAL inANDdecr_below_zero_and_mon_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D38= pd.DataFrame (inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D38.to_csv(\"FINAL inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D39= pd.DataFrame (mon_decr_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D39.to_csv(\"FINAL increasing below zero and increasing and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D40= pd.DataFrame (mon_decr_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D40.to_csv(\"FINAL increasing below zero and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D41= pd.DataFrame (mon_decr_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D41.to_csv(\"FINAL increasing below zero and increasing and stable above zero reactions cut off 2.csv\")\n",
    "D42= pd.DataFrame (mon_incr_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D42.to_csv(\"FINAL decreasing below zero and increasing and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D43= pd.DataFrame (mon_incr_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D43.to_csv(\"FINAL decreasing below zero and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D44= pd.DataFrame (mon_incr_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D44.to_csv(\"FINAL decreasing below zero and increasing and stable above zero reactions cut off 2.csv\")\n",
    "D45= pd.DataFrame (inANDdecr_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D45.to_csv(\"FINAL inANDdecr_below_zero_and_one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D46= pd.DataFrame (mon_decr_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D46.to_csv(\"FINAL increasing below zero and one to three data point above zero reactions cut off 2.csv\")\n",
    "D47= pd.DataFrame (mon_incr_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D47.to_csv(\"FINAL decreasing below zero and one to three data point above zero reactions cut off 2.csv\")\n",
    "D48= pd.DataFrame (flat_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D48.to_csv(\"FINAL flat_below_zero_and_inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D49= pd.DataFrame (flat_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D49.to_csv(\"FINAL flat_below_zero_and_mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D50= pd.DataFrame (flat_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D50.to_csv(\"FINAL flat_below_zero_and_mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D51= pd.DataFrame (flat_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D51.to_csv(\"FINAL flat_below_zero_and_inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D52= pd.DataFrame (flat_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D52.to_csv(\"FINAL flat_below_zero_and_mon_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D53= pd.DataFrame (flat_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D53.to_csv(\"FINAL flat_below_zero_and_mon_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D54= pd.DataFrame (inANDdecr_and_stable_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D54.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_flat_above_zero reactions cut off 2.csv\")\n",
    "D55= pd.DataFrame (mon_decr_and_stable_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D55.to_csv(\"FINAL increasing and stable below zero and flat above zero reactions cut off 2.csv\")\n",
    "D56= pd.DataFrame (mon_incr_and_stable_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D56.to_csv(\"FINAL decreasing and stable below zero and flat above zero reactions cut off 2.csv\")\n",
    "D57= pd.DataFrame (inANDdecr_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D57.to_csv(\"FINAL inANDdecr_below_zero_and_flat_above_zero reactions cut off 2.csv\")\n",
    "D58= pd.DataFrame (mon_decr_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D58.to_csv(\"FINAL increasing below zero and flat above zero reactions cut off 2.csv\")\n",
    "D59= pd.DataFrame (mon_incr_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D59.to_csv(\"FINAL decreasing below zero and flat above zero reactions cut off 2.csv\")\n",
    "D60= pd.DataFrame (inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D60.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D61= pd.DataFrame (inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D61.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D62= pd.DataFrame (inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D62.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D63= pd.DataFrame (mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D63.to_csv(\"FINAL increasing and stable below zero and increasing and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D64= pd.DataFrame (mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D64.to_csv(\"FINAL increasing and stable below zero and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D65= pd.DataFrame (mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D65.to_csv(\"FINAL increasing and stable below zero and increasing and stable above zero reactions cut off 2.csv\")\n",
    "D66= pd.DataFrame (mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D66.to_csv(\"FINAL decreasing and stable below zero and increasing and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D67= pd.DataFrame (mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D67.to_csv(\"FINAL decreasing and stable below zero and decreasing and stable above zero reactions cut off 2.csv\")\n",
    "D68= pd.DataFrame (mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D68.to_csv(\"FINAL decreasing and stable below zero and increasing and stable above zero reactions cut off 2.csv\")\n",
    "D69= pd.DataFrame (flat_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D69.to_csv(\"FINAL flat_below_zero_and_flat_above_zero reactions cut off 2.csv\")\n",
    "D70= pd.DataFrame (one_to_three_data_point_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D70.to_csv(\"FINAL one_to_three_data_point_below_zero_and_flat_above_zero reactions cut off 2.csv\")\n",
    "D71= pd.DataFrame (one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D71.to_csv(\"FINAL one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D72= pd.DataFrame (flat_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D72.to_csv(\"FINAL flat_below_zero_and_one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D73= pd.DataFrame (unclassified_above_zero, columns = ['Reaction names'])\n",
    "D73.to_csv(\"FINAL unclassified_above_zero reactions cut off 2.csv\")\n",
    "D74= pd.DataFrame (unclassified_below_zero, columns = ['Reaction names'])\n",
    "D74.to_csv(\"FINAL unclassified_below_zero reactions cut off 2.csv\")\n",
    "D75= pd.DataFrame (one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D75.to_csv(\"FINAL one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D76= pd.DataFrame (one_to_three_data_point_below_zero, columns = ['Reaction names'])\n",
    "D76.to_csv(\"FINAL one_to_three_data_point_below_zero reactions cut off 2.csv\")\n",
    "D77= pd.DataFrame (mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D77.to_csv(\"FINAL mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D78= pd.DataFrame (mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D78.to_csv(\"FINAL mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D79= pd.DataFrame (inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D79.to_csv(\"FINAL inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D80= pd.DataFrame (mon_decr_below_zero, columns = ['Reaction names'])\n",
    "D80.to_csv(\"FINAL increasing below zero reactions cut off 2.csv\")\n",
    "D81= pd.DataFrame (mon_incr_below_zero, columns = ['Reaction names'])\n",
    "D81.to_csv(\"FINAL decreasing below zero reactions cut off 2.csv\")\n",
    "D82= pd.DataFrame (inANDdecr_below_zero, columns = ['Reaction names'])\n",
    "D82.to_csv(\"FINAL inANDdecr_below_zero reactions cut off 2.csv\")\n",
    "D83= pd.DataFrame (unclassified_below_zero_and_one_to_three_data_point_above_zero, columns = ['Reaction names'])\n",
    "D83.to_csv(\"FINAL unclassified_below_zero_and_one_to_three_data_point_above_zero reactions cut off 2.csv\")\n",
    "D84= pd.DataFrame (unclassified_below_zero_and_mon_decr_above_zero, columns = ['Reaction names'])\n",
    "D84.to_csv(\"FINAL unclassified_below_zero_and_mon_decr_above_zero reactions cut off 2.csv\")\n",
    "D85= pd.DataFrame (unclassified_below_zero_and_mon_incr_above_zero, columns = ['Reaction names'])\n",
    "D85.to_csv(\"FINAL unclassified_below_zero_and_mon_incr_above_zero reactions cut off 2.csv\")\n",
    "D86= pd.DataFrame (unclassified_below_zero_and_inANDdecr_above_zero, columns = ['Reaction names'])\n",
    "D86.to_csv(\"FINAL unclassified_below_zero_and_inANDdecr_above_zero reactions cut off 2.csv\")\n",
    "D87= pd.DataFrame (one_to_three_data_point_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D87.to_csv(\"FINAL one_to_three_data_point_below_zero_and_unclassified_above_zero reactions cut off 2.csv\")\n",
    "D88= pd.DataFrame (inANDdecr_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D88.to_csv(\"FINAL inANDdecr_below_zero_and_unclassified_above_zero reactions cut off 2.csv\")\n",
    "D89= pd.DataFrame (mon_decr_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D89.to_csv(\"FINAL increasing below zero and unclassified above zero reactions cut off 2.csv\")\n",
    "D90= pd.DataFrame (mon_incr_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D90.to_csv(\"FINAL decreasing below zero and unclassified above zero reactions cut off 2.csv\")\n",
    "D91= pd.DataFrame (flat_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D91.to_csv(\"FINAL flat_below_zero_and_unclassified_above_zero reactions cut off 2.csv\")\n",
    "D92= pd.DataFrame (unclassified_below_zero_and_flat_above_zero, columns = ['Reaction names'])\n",
    "D92.to_csv(\"FINAL unclassified_below_zero_and_flat_above_zero reactions cut off 2.csv\")\n",
    "D93= pd.DataFrame (inANDdecr_and_stable_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D93.to_csv(\"FINAL inANDdecr_and_stable_below_zero_and_unclassified_above_zero reactions cut off 2.csv\")\n",
    "D94= pd.DataFrame (mon_decr_and_stable_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D94.to_csv(\"FINAL increasing and stable below zero and unclassified above zero reactions cut off 2.csv\")\n",
    "D95= pd.DataFrame (mon_incr_and_stable_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D95.to_csv(\"FINAL decreasing and stable below zero and unclassified above zero reactions cut off 2.csv\")\n",
    "D96= pd.DataFrame (unclassified_below_zero_and_unclassified_above_zero, columns = ['Reaction names'])\n",
    "D96.to_csv(\"FINAL unclassified_below_zero_and_unclassified_above_zero reactions cut off 2.csv\")\n",
    "D97= pd.DataFrame (unclassified_below_zero_and_mon_decr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D97.to_csv(\"FINAL unclassified_below_zero_and_mon_decr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D98= pd.DataFrame (unclassified_below_zero_and_mon_incr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D98.to_csv(\"FINAL unclassified_below_zero_and_mon_incr_and_stable_above_zero reactions cut off 2.csv\")\n",
    "D99= pd.DataFrame (unclassified_below_zero_and_inANDdecr_and_stable_above_zero, columns = ['Reaction names'])\n",
    "D99.to_csv(\"FINAL unclassified_below_zero_and_inANDdecr_and_stable_above_zero reactions cut off 2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "parental-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "proved-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one\n",
    "zero\n",
    "one_at_zero\n",
    "flat_above_zero\n",
    "flat_below_zero\n",
    "\n",
    "mon_decr_and_stable_above_zero\n",
    "mon_incr_and_stable_above_zero\n",
    "inANDdecr_and_stable_above_zero\n",
    "\n",
    "mon_decr_and_stable_below_zero\n",
    "mon_incr_and_stable_below_zero\n",
    "inANDdecr_and_stable_below_zero\n",
    "\n",
    "decr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n",
    "incr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero\n",
    "\n",
    "decr_and_stable_below_zero_and_mon_decr_above_zero\n",
    "incr_and_stable_below_zero_and_mon_decr_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_above_zero\n",
    "\n",
    "decr_and_stable_below_zero_and_mon_incr_above_zero\n",
    "incr_and_stable_below_zero_and_mon_incr_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_above_zero\n",
    "\n",
    "decr_and_stable_below_zero_and_inANDdecr_above_zero\n",
    "incr_and_stable_below_zero_and_inANDdecr_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero\n",
    "\n",
    "one_to_three_data_point_below_zero_and_decr_and_stable_above_zero\n",
    "one_to_three_data_point_below_zero_and_incr_and_stable_above_zero\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "\n",
    "one_to_three_data_point_below_zero_and_mon_decr_above_zero\n",
    "one_to_three_data_point_below_zero_and_mon_incr_above_zero\n",
    "one_to_three_data_point_below_zero_and_inANDdecr_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_mon_decr_above_zero\n",
    "mon_decr_below_zero_and_mon_decr_above_zero\n",
    "mon_incr_below_zero_and_mon_decr_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_mon_incr_above_zero\n",
    "mon_decr_below_zero_and_mon_incr_above_zero\n",
    "mon_incr_below_zero_and_mon_incr_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_inANDdecr_above_zero\n",
    "mon_decr_below_zero_and_inANDdecr_above_zero\n",
    "mon_incr_below_zero_and_inANDdecr_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_mon_decr_and_stable_above_zero\n",
    "inANDdecr_below_zero_and_mon_incr_and_stable_above_zero\n",
    "inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "\n",
    "mon_decr_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "mon_decr_below_zero_and_mon_decr_and_stable_above_zero\n",
    "mon_decr_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "mon_incr_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "mon_incr_below_zero_and_mon_decr_and_stable_above_zero\n",
    "mon_incr_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_one_to_three_data_point_above_zero\n",
    "mon_decr_below_zero_and_one_to_three_data_point_above_zero\n",
    "mon_incr_below_zero_and_one_to_three_data_point_above_zero\n",
    "\n",
    "flat_below_zero_and_inANDdecr_above_zero\n",
    "flat_below_zero_and_mon_decr_above_zero\n",
    "flat_below_zero_and_mon_incr_above_zero\n",
    "\n",
    "flat_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "flat_below_zero_and_mon_decr_and_stable_above_zero\n",
    "flat_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "inANDdecr_and_stable_below_zero_and_flat_above_zero\n",
    "mon_decr_and_stable_below_zero_and_flat_above_zero\n",
    "mon_incr_and_stable_below_zero_and_flat_above_zero\n",
    "\n",
    "inANDdecr_below_zero_and_flat_above_zero\n",
    "mon_decr_below_zero_and_flat_above_zero\n",
    "mon_incr_below_zero_and_flat_above_zero\n",
    "\n",
    "inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero\n",
    "mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\n",
    "mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero\n",
    "mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero\n",
    "\n",
    "flat_below_zero_and_flat_above_zero\n",
    "one_to_three_data_point_below_zero_and_flat_above_zero\n",
    "one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero\n",
    "flat_below_zero_and_one_to_three_data_point_above_zero\n",
    "\n",
    "unclassified_above_zero\n",
    "unclassified_below_zero\n",
    "one_to_three_data_point_above_zero\n",
    "one_to_three_data_point_below_zero\n",
    "\n",
    "mon_decr_above_zero\n",
    "mon_incr_above_zero\n",
    "inANDdecr_above_zero\n",
    "\n",
    "mon_decr_below_zero\n",
    "mon_incr_below_zero\n",
    "inANDdecr_below_zero\n",
    "\n",
    "unclassified_below_zero_and_one_to_three_data_point_above_zero\n",
    "unclassified_below_zero_and_mon_decr_above_zero\n",
    "unclassified_below_zero_and_mon_incr_above_zero\n",
    "unclassified_below_zero_and_inANDdecr_above_zero\n",
    "\n",
    "one_to_three_data_point_below_zero_and_unclassified_above_zero\n",
    "inANDdecr_below_zero_and_unclassified_above_zero\n",
    "mon_decr_below_zero_and_unclassified_above_zero\n",
    "mon_incr_below_zero_and_unclassified_above_zero\n",
    "\n",
    "flat_below_zero_and_unclassified_above_zero\n",
    "unclassified_below_zero_and_flat_above_zero\n",
    "inANDdecr_and_stable_below_zero_and_unclassified_above_zero\n",
    "mon_decr_and_stable_below_zero_and_unclassified_above_zero\n",
    "mon_incr_and_stable_below_zero_and_unclassified_above_zero\n",
    "unclassified_below_zero_and_unclassified_above_zero\n",
    "\n",
    "unclassified_below_zero_and_mon_decr_and_stable_above_zero\n",
    "unclassified_below_zero_and_mon_incr_and_stable_above_zero\n",
    "unclassified_below_zero_and_inANDdecr_and_stable_above_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "funky-looking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_below_zero_and_flat_above_zero)+ len(one_to_three_data_point_below_zero_and_flat_above_zero)+ len(one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero)+ len(flat_below_zero_and_one_to_three_data_point_above_zero)+ len(one_at_zero)+len(one)+len(zero)+len(mon_decr_and_stable_above_zero)+len(mon_incr_and_stable_above_zero)+len(inANDdecr_and_stable_above_zero)+len(mon_decr_and_stable_below_zero)+len(mon_incr_and_stable_below_zero)+len(inANDdecr_and_stable_below_zero)+len(flat_above_zero)+len(flat_below_zero)+len(mon_decr_above_zero)+len(mon_incr_above_zero)+len(inANDdecr_above_zero)+len(mon_decr_below_zero)+len(mon_incr_below_zero)+len(inANDdecr_below_zero)+len(decr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+len(incr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+len(inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+len(decr_and_stable_below_zero_and_mon_decr_above_zero)+len(incr_and_stable_below_zero_and_mon_decr_above_zero)+len(inANDdecr_and_stable_below_zero_and_mon_decr_above_zero)+len(decr_and_stable_below_zero_and_mon_incr_above_zero)+len(incr_and_stable_below_zero_and_mon_incr_above_zero)+len(inANDdecr_and_stable_below_zero_and_mon_incr_above_zero)+len(decr_and_stable_below_zero_and_inANDdecr_above_zero)+len(incr_and_stable_below_zero_and_inANDdecr_above_zero)+len(inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero)+len(one_to_three_data_point_below_zero_and_decr_and_stable_above_zero)+len(one_to_three_data_point_below_zero_and_incr_and_stable_above_zero)+len(one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero)+len(one_to_three_data_point_below_zero_and_mon_decr_above_zero)+len(one_to_three_data_point_below_zero_and_mon_incr_above_zero)+len(one_to_three_data_point_below_zero_and_inANDdecr_above_zero)+len(inANDdecr_below_zero_and_mon_decr_above_zero)+len(mon_decr_below_zero_and_mon_decr_above_zero)+len(mon_incr_below_zero_and_mon_decr_above_zero)+len(inANDdecr_below_zero_and_mon_incr_above_zero)+len(mon_decr_below_zero_and_mon_incr_above_zero)+len(mon_incr_below_zero_and_mon_incr_above_zero)+len(inANDdecr_below_zero_and_inANDdecr_above_zero)+len(mon_decr_below_zero_and_inANDdecr_above_zero)+len(mon_incr_below_zero_and_inANDdecr_above_zero)+len(inANDdecr_below_zero_and_mon_decr_and_stable_above_zero)+len(inANDdecr_below_zero_and_mon_incr_and_stable_above_zero)+len(inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero)+len(mon_decr_below_zero_and_inANDdecr_and_stable_above_zero)+len(mon_decr_below_zero_and_mon_decr_and_stable_above_zero)+len(mon_decr_below_zero_and_mon_incr_and_stable_above_zero)+len(mon_incr_below_zero_and_inANDdecr_and_stable_above_zero)+len(mon_incr_below_zero_and_mon_decr_and_stable_above_zero)+len(mon_incr_below_zero_and_mon_incr_and_stable_above_zero)+len(inANDdecr_below_zero_and_one_to_three_data_point_above_zero)+len(mon_decr_below_zero_and_one_to_three_data_point_above_zero)+len(mon_incr_below_zero_and_one_to_three_data_point_above_zero)+len(flat_below_zero_and_inANDdecr_above_zero)+len(flat_below_zero_and_mon_decr_above_zero)+len(flat_below_zero_and_mon_incr_above_zero)+len(flat_below_zero_and_inANDdecr_and_stable_above_zero)+len(flat_below_zero_and_mon_decr_and_stable_above_zero)+len(flat_below_zero_and_mon_incr_and_stable_above_zero)+len(inANDdecr_and_stable_below_zero_and_flat_above_zero)+len(mon_decr_and_stable_below_zero_and_flat_above_zero)+len(mon_incr_and_stable_below_zero_and_flat_above_zero)+len(inANDdecr_below_zero_and_flat_above_zero)+len(mon_decr_below_zero_and_flat_above_zero)+len(mon_incr_below_zero_and_flat_above_zero)+len(inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+len(inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+len(inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+len(mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+len(mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+len(mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+len(mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+len(mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+len(mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+len(unclassified_above_zero)+len(unclassified_below_zero)+len(one_to_three_data_point_below_zero)+len(one_to_three_data_point_above_zero)+len(unclassified_below_zero_and_one_to_three_data_point_above_zero)+len(unclassified_below_zero_and_mon_decr_above_zero)+len(unclassified_below_zero_and_mon_incr_above_zero)+len(unclassified_below_zero_and_inANDdecr_above_zero)+len(one_to_three_data_point_below_zero_and_unclassified_above_zero)+len(inANDdecr_below_zero_and_unclassified_above_zero)+len(mon_decr_below_zero_and_unclassified_above_zero)+len(mon_incr_below_zero_and_unclassified_above_zero)+len(flat_below_zero_and_unclassified_above_zero)+len(unclassified_below_zero_and_flat_above_zero)+len(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)+len(mon_decr_and_stable_below_zero_and_unclassified_above_zero)+len(mon_incr_and_stable_below_zero_and_unclassified_above_zero)+len(unclassified_below_zero_and_unclassified_above_zero)+len(unclassified_below_zero_and_mon_decr_and_stable_above_zero)+len(unclassified_below_zero_and_mon_incr_and_stable_above_zero)+len(unclassified_below_zero_and_inANDdecr_and_stable_above_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "organizational-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt= list(flat_below_zero_and_flat_above_zero)+ list(one_to_three_data_point_below_zero_and_flat_above_zero)+ list(one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero)+ list(flat_below_zero_and_one_to_three_data_point_above_zero)+ list(one_at_zero)+list(one)+list(zero)+list(mon_decr_and_stable_above_zero)+list(mon_incr_and_stable_above_zero)+list(inANDdecr_and_stable_above_zero)+list(mon_decr_and_stable_below_zero)+list(mon_incr_and_stable_below_zero)+list(inANDdecr_and_stable_below_zero)+list(flat_above_zero)+list(flat_below_zero)+list(mon_decr_above_zero)+list(mon_incr_above_zero)+list(inANDdecr_above_zero)+list(mon_decr_below_zero)+list(mon_incr_below_zero)+list(inANDdecr_below_zero)+list(decr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+list(incr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+list(inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero)+list(decr_and_stable_below_zero_and_mon_decr_above_zero)+list(incr_and_stable_below_zero_and_mon_decr_above_zero)+list(inANDdecr_and_stable_below_zero_and_mon_decr_above_zero)+list(decr_and_stable_below_zero_and_mon_incr_above_zero)+list(incr_and_stable_below_zero_and_mon_incr_above_zero)+list(inANDdecr_and_stable_below_zero_and_mon_incr_above_zero)+list(decr_and_stable_below_zero_and_inANDdecr_above_zero)+list(incr_and_stable_below_zero_and_inANDdecr_above_zero)+list(inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero)+list(one_to_three_data_point_below_zero_and_decr_and_stable_above_zero)+list(one_to_three_data_point_below_zero_and_incr_and_stable_above_zero)+list(one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero)+list(one_to_three_data_point_below_zero_and_mon_decr_above_zero)+list(one_to_three_data_point_below_zero_and_mon_incr_above_zero)+list(one_to_three_data_point_below_zero_and_inANDdecr_above_zero)+list(inANDdecr_below_zero_and_mon_decr_above_zero)+list(mon_decr_below_zero_and_mon_decr_above_zero)+list(mon_incr_below_zero_and_mon_decr_above_zero)+list(inANDdecr_below_zero_and_mon_incr_above_zero)+list(mon_decr_below_zero_and_mon_incr_above_zero)+list(mon_incr_below_zero_and_mon_incr_above_zero)+list(inANDdecr_below_zero_and_inANDdecr_above_zero)+list(mon_decr_below_zero_and_inANDdecr_above_zero)+list(mon_incr_below_zero_and_inANDdecr_above_zero)+list(inANDdecr_below_zero_and_mon_decr_and_stable_above_zero)+list(inANDdecr_below_zero_and_mon_incr_and_stable_above_zero)+list(inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero)+list(mon_decr_below_zero_and_inANDdecr_and_stable_above_zero)+list(mon_decr_below_zero_and_mon_decr_and_stable_above_zero)+list(mon_decr_below_zero_and_mon_incr_and_stable_above_zero)+list(mon_incr_below_zero_and_inANDdecr_and_stable_above_zero)+list(mon_incr_below_zero_and_mon_decr_and_stable_above_zero)+list(mon_incr_below_zero_and_mon_incr_and_stable_above_zero)+list(inANDdecr_below_zero_and_one_to_three_data_point_above_zero)+list(mon_decr_below_zero_and_one_to_three_data_point_above_zero)+list(mon_incr_below_zero_and_one_to_three_data_point_above_zero)+list(flat_below_zero_and_inANDdecr_above_zero)+list(flat_below_zero_and_mon_decr_above_zero)+list(flat_below_zero_and_mon_incr_above_zero)+list(flat_below_zero_and_inANDdecr_and_stable_above_zero)+list(flat_below_zero_and_mon_decr_and_stable_above_zero)+list(flat_below_zero_and_mon_incr_and_stable_above_zero)+list(inANDdecr_and_stable_below_zero_and_flat_above_zero)+list(mon_decr_and_stable_below_zero_and_flat_above_zero)+list(mon_incr_and_stable_below_zero_and_flat_above_zero)+list(inANDdecr_below_zero_and_flat_above_zero)+list(mon_decr_below_zero_and_flat_above_zero)+list(mon_incr_below_zero_and_flat_above_zero)+list(inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+list(inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+list(inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+list(mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+list(mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+list(mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+list(mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero)+list(mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero)+list(mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero)+list(unclassified_above_zero)+list(unclassified_below_zero)+list(one_to_three_data_point_below_zero)+list(one_to_three_data_point_above_zero)+list(unclassified_below_zero_and_one_to_three_data_point_above_zero)+list(unclassified_below_zero_and_mon_decr_above_zero)+list(unclassified_below_zero_and_mon_incr_above_zero)+list(unclassified_below_zero_and_inANDdecr_above_zero)+list(one_to_three_data_point_below_zero_and_unclassified_above_zero)+list(inANDdecr_below_zero_and_unclassified_above_zero)+list(mon_decr_below_zero_and_unclassified_above_zero)+list(mon_incr_below_zero_and_unclassified_above_zero)+list(flat_below_zero_and_unclassified_above_zero)+list(unclassified_below_zero_and_flat_above_zero)+list(inANDdecr_and_stable_below_zero_and_unclassified_above_zero)+list(mon_decr_and_stable_below_zero_and_unclassified_above_zero)+list(mon_incr_and_stable_below_zero_and_unclassified_above_zero)+list(unclassified_below_zero_and_unclassified_above_zero)+list(unclassified_below_zero_and_mon_decr_and_stable_above_zero)+list(unclassified_below_zero_and_mon_incr_and_stable_above_zero)+list(unclassified_below_zero_and_inANDdecr_and_stable_above_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "waiting-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[]\n",
    "for i in lt:\n",
    "    if i not in l1:\n",
    "        l1.append(i)\n",
    "    else:\n",
    "        print(i,end=' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "grateful-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFile = pd.read_csv('all reactions.csv')\n",
    "csvFile[\"Reaction names\"]\n",
    "\n",
    "rl= list(csvFile[\"Reaction names\"])\n",
    "\n",
    "set1= set(rl)\n",
    "set2= set(lt)\n",
    "set3= set1-set2\n",
    "set3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "ethical-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "csvFile = pd.read_csv('NEW different reactions glu vs lac cut off 2.csv')\n",
    "csvFile[\"Category in glucose\"] = \"\"\n",
    "csvFile\n",
    "\n",
    "while i < len(csvFile):\n",
    "    if csvFile.iloc[i, 1] in one:\n",
    "        csvFile.iloc[i, 2] = \"one\"\n",
    "    if csvFile.iloc[i, 1] in zero:\n",
    "        csvFile.iloc[i, 2] = \"zero\"\n",
    "    if csvFile.iloc[i, 1] in one_at_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_at_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"mon_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"mon_incr_and_stable_above_zero\"   \n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero\"\n",
    "    if csvFile.iloc[i, 1] in decr_and_stable_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and one to three data point above zero\"\n",
    "    if csvFile.iloc[i, 1] in incr_and_stable_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and one to three data point above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in decr_and_stable_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in incr_and_stable_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_mon_decr_above_zero\"   \n",
    "    if csvFile.iloc[i, 1] in decr_and_stable_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and increasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in incr_and_stable_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and increasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in decr_and_stable_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and increasing and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in incr_and_stable_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and increasing and decreasing above zero\"   \n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_incr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_inANDdecr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_mon_decr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_mon_decr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and decreasing above zero\"   \n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and increasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and increasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and increasing and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and increasing and decreasing above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_mon_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_mon_incr_and_stable_above_zero\"   \n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_inANDdecr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and increasing and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and increasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and increasing and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and increasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and one to three data point above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and one to three data point above zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_mon_decr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_inANDdecr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_mon_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_mon_incr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and flat above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and flat above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and flat above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and flat above zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_mon_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_mon_incr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and inANDdecr_and_stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and increasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and inANDdecr_and_stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and decreasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and increasing and stable above zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"mon_decr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_one_to_three_data_point_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_one_to_three_data_point_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_mon_decr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_mon_decr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_mon_incr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_mon_incr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_inANDdecr_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_inANDdecr_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in one_to_three_data_point_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"one_to_three_data_point_below_zero_and_unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_below_zero_and_unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing below zero and unclassified above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing below zero and unclassified above zero\"\n",
    "    if csvFile.iloc[i, 1] in flat_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"flat_below_zero_and_unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_flat_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_flat_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in inANDdecr_and_stable_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"inANDdecr_and_stable_below_zero_and_unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_decr_and_stable_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"increasing and stable below zero and unclassified above zero\"\n",
    "    if csvFile.iloc[i, 1] in mon_incr_and_stable_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"decreasing and stable below zero and unclassified above zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_unclassified_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_unclassified_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_mon_decr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_mon_decr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_mon_incr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_mon_incr_and_stable_above_zero\"\n",
    "    if csvFile.iloc[i, 1] in unclassified_below_zero_and_inANDdecr_and_stable_above_zero:\n",
    "        csvFile.iloc[i, 2] = \"unclassified_below_zero_and_inANDdecr_and_stable_above_zero\"\n",
    "\n",
    "    i= i+1\n",
    "\n",
    "csvFile\n",
    "csvFile.to_csv(\"FINAL different reactions glu vs lac cut off 2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
